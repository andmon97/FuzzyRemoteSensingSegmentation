{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANFIS_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05b34ce6cc8047e0bfcfe28d972a5dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_087f20d2a103401594e8a01d405dccec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db356e34ef814e60aad7a14f85b43a4b",
              "IPY_MODEL_ba36833ae3ea429fa159cab694815ac8"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "087f20d2a103401594e8a01d405dccec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "db356e34ef814e60aad7a14f85b43a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea9ebba00376499490ea3c75fc5b61eb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5154f1ca0f6447fa7030289c312419f"
          },
          "model_module_version": "1.5.0"
        },
        "ba36833ae3ea429fa159cab694815ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb36f60cf5904aaa94ec1f9c4d35e7ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [3:39:13&lt;00:00, 65.77s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_600c46189841477493c9070d53edb1c2"
          },
          "model_module_version": "1.5.0"
        },
        "ea9ebba00376499490ea3c75fc5b61eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "c5154f1ca0f6447fa7030289c312419f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cb36f60cf5904aaa94ec1f9c4d35e7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "600c46189841477493c9070d53edb1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5db64db0ddcd490896165bf494b4948e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f039b94c1fd3436bbd7ea0921e597e39",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc8250a626bb4104bd1d68f0f7c16571",
              "IPY_MODEL_bdd4c9711b54497899e34b9c588938d6"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "f039b94c1fd3436bbd7ea0921e597e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "dc8250a626bb4104bd1d68f0f7c16571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0ea6c66e68643409f2adc8912886133",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_311bec319b204ec8b36b9fd9abaf0019"
          },
          "model_module_version": "1.5.0"
        },
        "bdd4c9711b54497899e34b9c588938d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cc7e2add88f43c287e343aeeec62e4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [5:20:08&lt;00:00, 96.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d71b47e4ee9449d98398fff0804ceae"
          },
          "model_module_version": "1.5.0"
        },
        "b0ea6c66e68643409f2adc8912886133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "311bec319b204ec8b36b9fd9abaf0019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "2cc7e2add88f43c287e343aeeec62e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "7d71b47e4ee9449d98398fff0804ceae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "e1d40b72ec90411ca7c8e83393e3cbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9af9208ae8a4aa1943ea858b9f10518",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9ee658c147446ed9dbdfa1b5dd2e1ad",
              "IPY_MODEL_71e7eb62bcf4428ab984e1262912c66f"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "f9af9208ae8a4aa1943ea858b9f10518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "b9ee658c147446ed9dbdfa1b5dd2e1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e651602a51394ed09ea47aaa87be1493",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b412dc9d20304ccf84fac639e12487fa"
          },
          "model_module_version": "1.5.0"
        },
        "71e7eb62bcf4428ab984e1262912c66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9eb2b5815424654b6e861ea9936d562",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [7:15:16&lt;00:00, 130.58s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7561bc2dbbd40159e1160a9db4d1fea"
          },
          "model_module_version": "1.5.0"
        },
        "e651602a51394ed09ea47aaa87be1493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "b412dc9d20304ccf84fac639e12487fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a9eb2b5815424654b6e861ea9936d562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "d7561bc2dbbd40159e1160a9db4d1fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7pnMz3BosnO"
      },
      "source": [
        "Mount Google Drive env to import the modules and the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KMt8TsUnPuf",
        "outputId": "24671f06-99e8-4160-ec0e-c4ff77940d9a"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9z9xyXfGJyr"
      },
      "source": [
        "# Append the directory to our python path using sys\n",
        "\n",
        "Now we are able to import stuff from that directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSc81qI8IBue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e6c6e2-6f74-476c-e496-1374460c5e7b"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ANFIS-imgSatellitari')\n",
        "%cd /content/drive/MyDrive/ANFIS-imgSatellitari/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ANFIS-imgSatellitari\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuh4dIZ0cTbA"
      },
      "source": [
        "Import all the libraries and modules.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIJm0r5GY3TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f505b5c6-4632-45bf-ca8e-33dafe0598c7"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from training import train_model\n",
        "from testMod import test_model\n",
        "import anfis\n",
        "from membership import *\n",
        "from utility import load_model, plot_import, split_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Begin training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_pB84keddZJ"
      },
      "source": [
        "# Test 1\n",
        "\n",
        "In the following test I choose to configure the ANFIS training with:\n",
        "\n",
        "\n",
        "*   Nr. 2 Fuzzy Sets\n",
        "*   32 of Batch size\n",
        "*   Nr. 200 of epochs\n",
        "\n",
        "CLASSI NELLE METRICHE:\n",
        "0 = BUILDING\n",
        "1 = ROAD\n",
        "2 = PAVEMENT\n",
        "3 = VEGETATION\n",
        "4 = BARE SOIL\n",
        "5 = WATER\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05b34ce6cc8047e0bfcfe28d972a5dba",
            "087f20d2a103401594e8a01d405dccec",
            "db356e34ef814e60aad7a14f85b43a4b",
            "ba36833ae3ea429fa159cab694815ac8",
            "ea9ebba00376499490ea3c75fc5b61eb",
            "c5154f1ca0f6447fa7030289c312419f",
            "cb36f60cf5904aaa94ec1f9c4d35e7ab",
            "600c46189841477493c9070d53edb1c2"
          ]
        },
        "id": "6OxTgaIpHpEh",
        "outputId": "8f923e45-d923-4d2e-d783-9dfc5989d64a"
      },
      "source": [
        "dataset = 'datasets/reducedTopClass/reducedTC.csv'\n",
        "model = None\n",
        "n_terms = 2 #IMPOSTA NUMERO DI FUZZY SET\n",
        "num_categories = 6 #IMPOSTA NUMERO DI CLASSI\n",
        "batch_size = 32\n",
        "epoch = 200\n",
        "model_l = False #SEMPRE A FALSE\n",
        "hybrid = False #SEMPRE A FALSE\n",
        "i = 0\n",
        "lista_acc = []\n",
        "k_fold = False\n",
        "\n",
        "# Make the classes available via (controlled) reflection:\n",
        "get_class_for = {n: globals()[n]\n",
        "                 for n in ['BellMembFunc',\n",
        "                           'GaussMembFunc',\n",
        "                           'TriangularMembFunc',\n",
        "                           'TrapezoidalMembFunc',\n",
        "                           ]}\n",
        "\n",
        "# DEFINIRE LA MEMBERSHIP FUNCTION ATTUALMENTE E' ABILITATA SOLO GAUSSIANA E TRIANGOLARE\n",
        "membership_function = get_class_for['GaussMembFunc']\n",
        "\n",
        "d_data, d_target = split_dataset(dataset)\n",
        "\n",
        "\n",
        "# Split train into trainval-test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(d_data, d_target, test_size=0.3, shuffle=True,\n",
        "                                                          stratify=d_target, random_state=42)\n",
        "\n",
        "# Split train into train-val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, shuffle=True,\n",
        "                                               stratify=y_trainval, random_state=42)\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val, n_terms, num_categories,\n",
        "                                   batch_size, epoch, model_l, hybrid, membership_function, i)\n",
        "\n",
        "torch.save(model, 'models/G_model_geo_' + str(2) + 'topClass' + '.h5')\n",
        "\n",
        "model = torch.load('models/G_model_geo_2topClass.h5')\n",
        "\n",
        "test_model(model, X_test, y_test, num_categories, k_fold, i, lista_acc)\n",
        "\n",
        "model = torch.load('models/G_model_geo_2topClass.h5')\n",
        "\n",
        "X_test = torch.Tensor(X_test)\n",
        "\n",
        "y_pred = model(X_test)\n",
        "\n",
        "cat_act = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "#PREDIZIONE SUI DATI DI TEST\n",
        "print(cat_act)\n",
        "\n",
        "cm = confusion_matrix(y_test, cat_act)\n",
        "print(cm)\n",
        "\n",
        "cl = classification_report(y_test, cat_act)\n",
        "print(cl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Model - Pre-training\n",
            "AnfisNet(\n",
            "  Rule  0: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  1: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  2: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  3: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  4: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  5: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  6: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  7: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  8: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  9: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 10: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 11: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 12: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 13: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 14: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 15: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  (layer): ModuleDict(\n",
            "    (fuzzify): Input variables\n",
            "    Variable x0\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=125.0)\n",
            "    - mf1: GaussMembFunc(mu=250.0, sigma=125.0)\n",
            "    Variable x1\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=127.5)\n",
            "    - mf1: GaussMembFunc(mu=255.0, sigma=127.5)\n",
            "    Variable x2\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=127.5)\n",
            "    - mf1: GaussMembFunc(mu=255.0, sigma=127.5)\n",
            "    Variable x3\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=2.428990602493286)\n",
            "    - mf1: GaussMembFunc(mu=4.857981204986572, sigma=2.428990602493286)\n",
            "    (rules): AntecedentLayer()\n",
            "    (consequent): PlainConsequentLayer()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05b34ce6cc8047e0bfcfe28d972a5dba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best epoch 1\n",
            "Epoch 001: | Train Loss: 0.94070166 | Val Loss: 0.84118672 | Train Acc: 0.67375613| Val Acc: 0.71444898\n",
            "best epoch 2\n",
            "Epoch 002: | Train Loss: 0.81825025 | Val Loss: 0.80433666 | Train Acc: 0.72111856| Val Acc: 0.72614104\n",
            "best epoch 3\n",
            "Epoch 003: | Train Loss: 0.79588451 | Val Loss: 0.79019690 | Train Acc: 0.72948056| Val Acc: 0.73155443\n",
            "best epoch 4\n",
            "Epoch 004: | Train Loss: 0.78483252 | Val Loss: 0.78119989 | Train Acc: 0.73387197| Val Acc: 0.73463625\n",
            "best epoch 5\n",
            "Epoch 005: | Train Loss: 0.77718386 | Val Loss: 0.77447413 | Train Acc: 0.73679235| Val Acc: 0.73690688\n",
            "best epoch 6\n",
            "Epoch 006: | Train Loss: 0.77128780 | Val Loss: 0.76915423 | Train Acc: 0.73880414| Val Acc: 0.73877788\n",
            "best epoch 7\n",
            "Epoch 007: | Train Loss: 0.76657394 | Val Loss: 0.76484328 | Train Acc: 0.74032243| Val Acc: 0.74041880\n",
            "best epoch 8\n",
            "Epoch 008: | Train Loss: 0.76275768 | Val Loss: 0.76131413 | Train Acc: 0.74151528| Val Acc: 0.74135733\n",
            "best epoch 9\n",
            "Epoch 009: | Train Loss: 0.75965047 | Val Loss: 0.75840930 | Train Acc: 0.74236147| Val Acc: 0.74230191\n",
            "best epoch 10\n",
            "Epoch 010: | Train Loss: 0.75710643 | Val Loss: 0.75600383 | Train Acc: 0.74308807| Val Acc: 0.74301640\n",
            "best epoch 11\n",
            "Epoch 011: | Train Loss: 0.75500676 | Val Loss: 0.75399411 | Train Acc: 0.74368903| Val Acc: 0.74345237\n",
            "best epoch 12\n",
            "Epoch 012: | Train Loss: 0.75325588 | Val Loss: 0.75229655 | Train Acc: 0.74419008| Val Acc: 0.74412447\n",
            "best epoch 13\n",
            "Epoch 013: | Train Loss: 0.75177883 | Val Loss: 0.75084634 | Train Acc: 0.74462150| Val Acc: 0.74474209\n",
            "best epoch 14\n",
            "Epoch 014: | Train Loss: 0.75051759 | Val Loss: 0.74959273 | Train Acc: 0.74492880| Val Acc: 0.74525676\n",
            "best epoch 15\n",
            "Epoch 015: | Train Loss: 0.74942768 | Val Loss: 0.74849750 | Train Acc: 0.74513921| Val Acc: 0.74560190\n",
            "best epoch 16\n",
            "Epoch 016: | Train Loss: 0.74847501 | Val Loss: 0.74753062 | Train Acc: 0.74536022| Val Acc: 0.74593493\n",
            "best epoch 17\n",
            "Epoch 017: | Train Loss: 0.74763341 | Val Loss: 0.74666933 | Train Acc: 0.74552825| Val Acc: 0.74618924\n",
            "best epoch 18\n",
            "Epoch 018: | Train Loss: 0.74688270 | Val Loss: 0.74589548 | Train Acc: 0.74560393| Val Acc: 0.74640722\n",
            "best epoch 19\n",
            "Epoch 019: | Train Loss: 0.74620732 | Val Loss: 0.74519518 | Train Acc: 0.74572049| Val Acc: 0.74656465\n",
            "best epoch 20\n",
            "Epoch 020: | Train Loss: 0.74559501 | Val Loss: 0.74455689 | Train Acc: 0.74580072| Val Acc: 0.74684924\n",
            "best epoch 21\n",
            "Epoch 021: | Train Loss: 0.74503618 | Val Loss: 0.74397173 | Train Acc: 0.74588701| Val Acc: 0.74710960\n",
            "best epoch 22\n",
            "Epoch 022: | Train Loss: 0.74452302 | Val Loss: 0.74343249 | Train Acc: 0.74592334| Val Acc: 0.74734575\n",
            "best epoch 23\n",
            "Epoch 023: | Train Loss: 0.74404933 | Val Loss: 0.74293322 | Train Acc: 0.74600508| Val Acc: 0.74747896\n",
            "best epoch 24\n",
            "Epoch 024: | Train Loss: 0.74361004 | Val Loss: 0.74246895 | Train Acc: 0.74609439| Val Acc: 0.74753951\n",
            "best epoch 25\n",
            "Epoch 025: | Train Loss: 0.74320090 | Val Loss: 0.74203564 | Train Acc: 0.74616856| Val Acc: 0.74757584\n",
            "best epoch 26\n",
            "Epoch 026: | Train Loss: 0.74281849 | Val Loss: 0.74162994 | Train Acc: 0.74623063| Val Acc: 0.74773933\n",
            "best epoch 27\n",
            "Epoch 027: | Train Loss: 0.74245989 | Val Loss: 0.74124885 | Train Acc: 0.74631540| Val Acc: 0.74786043\n",
            "best epoch 28\n",
            "Epoch 028: | Train Loss: 0.74212255 | Val Loss: 0.74088986 | Train Acc: 0.74642136| Val Acc: 0.74792098\n",
            "best epoch 29\n",
            "Epoch 029: | Train Loss: 0.74180437 | Val Loss: 0.74055102 | Train Acc: 0.74654549| Val Acc: 0.74796942\n",
            "best epoch 30\n",
            "Epoch 030: | Train Loss: 0.74150351 | Val Loss: 0.74023018 | Train Acc: 0.74660755| Val Acc: 0.74801786\n",
            "best epoch 31\n",
            "Epoch 031: | Train Loss: 0.74121840 | Val Loss: 0.73992620 | Train Acc: 0.74665297| Val Acc: 0.74809657\n",
            "best epoch 32\n",
            "Epoch 032: | Train Loss: 0.74094767 | Val Loss: 0.73963722 | Train Acc: 0.74672260| Val Acc: 0.74815107\n",
            "best epoch 33\n",
            "Epoch 033: | Train Loss: 0.74069013 | Val Loss: 0.73936231 | Train Acc: 0.74680283| Val Acc: 0.74826611\n",
            "best epoch 34\n",
            "Epoch 034: | Train Loss: 0.74044467 | Val Loss: 0.73910025 | Train Acc: 0.74690274| Val Acc: 0.74834483\n",
            "best epoch 35\n",
            "Epoch 035: | Train Loss: 0.74021041 | Val Loss: 0.73885004 | Train Acc: 0.74697691| Val Acc: 0.74839327\n",
            "best epoch 36\n",
            "Epoch 036: | Train Loss: 0.73998644 | Val Loss: 0.73861073 | Train Acc: 0.74705108| Val Acc: 0.74845382\n",
            "best epoch 37\n",
            "Epoch 037: | Train Loss: 0.73977201 | Val Loss: 0.73838177 | Train Acc: 0.74709044| Val Acc: 0.74849620\n",
            "best epoch 38\n",
            "Epoch 038: | Train Loss: 0.73956651 | Val Loss: 0.73816223 | Train Acc: 0.74716008| Val Acc: 0.74844776\n",
            "best epoch 39\n",
            "Epoch 039: | Train Loss: 0.73936928 | Val Loss: 0.73795176 | Train Acc: 0.74723576| Val Acc: 0.74854464\n",
            "best epoch 40\n",
            "Epoch 040: | Train Loss: 0.73917980 | Val Loss: 0.73774941 | Train Acc: 0.74728723| Val Acc: 0.74857492\n",
            "best epoch 41\n",
            "Epoch 041: | Train Loss: 0.73899758 | Val Loss: 0.73755483 | Train Acc: 0.74731902| Val Acc: 0.74858703\n",
            "best epoch 42\n",
            "Epoch 042: | Train Loss: 0.73882213 | Val Loss: 0.73736759 | Train Acc: 0.74736141| Val Acc: 0.74862942\n",
            "best epoch 43\n",
            "Epoch 043: | Train Loss: 0.73865307 | Val Loss: 0.73718712 | Train Acc: 0.74743255| Val Acc: 0.74866575\n",
            "best epoch 44\n",
            "Epoch 044: | Train Loss: 0.73849002 | Val Loss: 0.73701331 | Train Acc: 0.74747191| Val Acc: 0.74875071\n",
            "best epoch 45\n",
            "Epoch 045: | Train Loss: 0.73833258 | Val Loss: 0.73684530 | Train Acc: 0.74751581| Val Acc: 0.74877493\n",
            "best epoch 46\n",
            "Epoch 046: | Train Loss: 0.73818049 | Val Loss: 0.73668320 | Train Acc: 0.74755971| Val Acc: 0.74870833\n",
            "best epoch 47\n",
            "Epoch 047: | Train Loss: 0.73803344 | Val Loss: 0.73652643 | Train Acc: 0.74758090| Val Acc: 0.74870833\n",
            "best epoch 48\n",
            "Epoch 048: | Train Loss: 0.73789116 | Val Loss: 0.73637486 | Train Acc: 0.74761874| Val Acc: 0.74868411\n",
            "best epoch 49\n",
            "Epoch 049: | Train Loss: 0.73775339 | Val Loss: 0.73622810 | Train Acc: 0.74767627| Val Acc: 0.74876888\n",
            "best epoch 50\n",
            "Epoch 050: | Train Loss: 0.73761991 | Val Loss: 0.73608602 | Train Acc: 0.74771108| Val Acc: 0.74879310\n",
            "best epoch 51\n",
            "Epoch 051: | Train Loss: 0.73749053 | Val Loss: 0.73594834 | Train Acc: 0.74776104| Val Acc: 0.74880521\n",
            "best epoch 52\n",
            "Epoch 052: | Train Loss: 0.73736503 | Val Loss: 0.73581485 | Train Acc: 0.74781250| Val Acc: 0.74874446\n",
            "best epoch 53\n",
            "Epoch 053: | Train Loss: 0.73724322 | Val Loss: 0.73568526 | Train Acc: 0.74783067| Val Acc: 0.74878079\n",
            "best epoch 54\n",
            "Epoch 054: | Train Loss: 0.73712493 | Val Loss: 0.73555940 | Train Acc: 0.74789122| Val Acc: 0.74879290\n",
            "best epoch 55\n",
            "Epoch 055: | Train Loss: 0.73700998 | Val Loss: 0.73543727 | Train Acc: 0.74793966| Val Acc: 0.74877474\n",
            "best epoch 56\n",
            "Epoch 056: | Train Loss: 0.73689821 | Val Loss: 0.73531852 | Train Acc: 0.74796842| Val Acc: 0.74885345\n",
            "best epoch 57\n",
            "Epoch 057: | Train Loss: 0.73678953 | Val Loss: 0.73520305 | Train Acc: 0.74802292| Val Acc: 0.74889584\n",
            "best epoch 58\n",
            "Epoch 058: | Train Loss: 0.73668372 | Val Loss: 0.73509079 | Train Acc: 0.74803957| Val Acc: 0.74893217\n",
            "best epoch 59\n",
            "Epoch 059: | Train Loss: 0.73658073 | Val Loss: 0.73498146 | Train Acc: 0.74808347| Val Acc: 0.74888978\n",
            "best epoch 60\n",
            "Epoch 060: | Train Loss: 0.73648042 | Val Loss: 0.73487497 | Train Acc: 0.74815461| Val Acc: 0.74896244\n",
            "best epoch 61\n",
            "Epoch 061: | Train Loss: 0.73638267 | Val Loss: 0.73477125 | Train Acc: 0.74818186| Val Acc: 0.74895639\n",
            "best epoch 62\n",
            "Epoch 062: | Train Loss: 0.73628738 | Val Loss: 0.73467027 | Train Acc: 0.74822425| Val Acc: 0.74900483\n",
            "best epoch 63\n",
            "Epoch 063: | Train Loss: 0.73619445 | Val Loss: 0.73457177 | Train Acc: 0.74826815| Val Acc: 0.74897455\n",
            "best epoch 64\n",
            "Epoch 064: | Train Loss: 0.73610379 | Val Loss: 0.73447563 | Train Acc: 0.74828934| Val Acc: 0.74899272\n",
            "best epoch 65\n",
            "Epoch 065: | Train Loss: 0.73601532 | Val Loss: 0.73438188 | Train Acc: 0.74833172| Val Acc: 0.74892006\n",
            "best epoch 66\n",
            "Epoch 066: | Train Loss: 0.73592895 | Val Loss: 0.73429037 | Train Acc: 0.74834989| Val Acc: 0.74896850\n",
            "best epoch 67\n",
            "Epoch 067: | Train Loss: 0.73584459 | Val Loss: 0.73420113 | Train Acc: 0.74838016| Val Acc: 0.74899877\n",
            "best epoch 68\n",
            "Epoch 068: | Train Loss: 0.73576215 | Val Loss: 0.73411386 | Train Acc: 0.74841498| Val Acc: 0.74904721\n",
            "best epoch 69\n",
            "Epoch 069: | Train Loss: 0.73568159 | Val Loss: 0.73402859 | Train Acc: 0.74845282| Val Acc: 0.74910776\n",
            "best epoch 70\n",
            "Epoch 070: | Train Loss: 0.73560287 | Val Loss: 0.73394531 | Train Acc: 0.74846948| Val Acc: 0.74915015\n",
            "best epoch 71\n",
            "Epoch 071: | Train Loss: 0.73552585 | Val Loss: 0.73386378 | Train Acc: 0.74850732| Val Acc: 0.74925914\n",
            "best epoch 72\n",
            "Epoch 072: | Train Loss: 0.73545047 | Val Loss: 0.73378420 | Train Acc: 0.74851943| Val Acc: 0.74927730\n",
            "best epoch 73\n",
            "Epoch 073: | Train Loss: 0.73537673 | Val Loss: 0.73370614 | Train Acc: 0.74853305| Val Acc: 0.74933180\n",
            "best epoch 74\n",
            "Epoch 074: | Train Loss: 0.73530456 | Val Loss: 0.73362994 | Train Acc: 0.74854668| Val Acc: 0.74932574\n",
            "best epoch 75\n",
            "Epoch 075: | Train Loss: 0.73523391 | Val Loss: 0.73355527 | Train Acc: 0.74856636| Val Acc: 0.74936207\n",
            "best epoch 76\n",
            "Epoch 076: | Train Loss: 0.73516470 | Val Loss: 0.73348224 | Train Acc: 0.74859663| Val Acc: 0.74935602\n",
            "best epoch 77\n",
            "Epoch 077: | Train Loss: 0.73509691 | Val Loss: 0.73341062 | Train Acc: 0.74860571| Val Acc: 0.74936207\n",
            "best epoch 78\n",
            "Epoch 078: | Train Loss: 0.73503049 | Val Loss: 0.73334046 | Train Acc: 0.74862691| Val Acc: 0.74938024\n",
            "best epoch 79\n",
            "Epoch 079: | Train Loss: 0.73496542 | Val Loss: 0.73327181 | Train Acc: 0.74867686| Val Acc: 0.74940446\n",
            "best epoch 80\n",
            "Epoch 080: | Train Loss: 0.73490161 | Val Loss: 0.73320449 | Train Acc: 0.74869654| Val Acc: 0.74941657\n",
            "best epoch 81\n",
            "Epoch 081: | Train Loss: 0.73483901 | Val Loss: 0.73313829 | Train Acc: 0.74871773| Val Acc: 0.74944684\n",
            "best epoch 82\n",
            "Epoch 082: | Train Loss: 0.73477761 | Val Loss: 0.73307362 | Train Acc: 0.74873590| Val Acc: 0.74944684\n",
            "best epoch 83\n",
            "Epoch 083: | Train Loss: 0.73471741 | Val Loss: 0.73301016 | Train Acc: 0.74875255| Val Acc: 0.74950134\n",
            "best epoch 84\n",
            "Epoch 084: | Train Loss: 0.73465833 | Val Loss: 0.73294789 | Train Acc: 0.74878282| Val Acc: 0.74950134\n",
            "best epoch 85\n",
            "Epoch 085: | Train Loss: 0.73460034 | Val Loss: 0.73288664 | Train Acc: 0.74879191| Val Acc: 0.74958611\n",
            "best epoch 86\n",
            "Epoch 086: | Train Loss: 0.73454343 | Val Loss: 0.73282671 | Train Acc: 0.74880250| Val Acc: 0.74959216\n",
            "best epoch 87\n",
            "Epoch 087: | Train Loss: 0.73448752 | Val Loss: 0.73276781 | Train Acc: 0.74882369| Val Acc: 0.74958611\n",
            "best epoch 88\n",
            "Epoch 088: | Train Loss: 0.73443260 | Val Loss: 0.73270986 | Train Acc: 0.74884943| Val Acc: 0.74959216\n",
            "best epoch 89\n",
            "Epoch 089: | Train Loss: 0.73437867 | Val Loss: 0.73265306 | Train Acc: 0.74887365| Val Acc: 0.74961638\n",
            "best epoch 90\n",
            "Epoch 090: | Train Loss: 0.73432567 | Val Loss: 0.73259719 | Train Acc: 0.74888879| Val Acc: 0.74964666\n",
            "best epoch 91\n",
            "Epoch 091: | Train Loss: 0.73427360 | Val Loss: 0.73254238 | Train Acc: 0.74890241| Val Acc: 0.74965877\n",
            "best epoch 92\n",
            "Epoch 092: | Train Loss: 0.73422240 | Val Loss: 0.73248855 | Train Acc: 0.74893571| Val Acc: 0.74965877\n",
            "best epoch 93\n",
            "Epoch 093: | Train Loss: 0.73417207 | Val Loss: 0.73243559 | Train Acc: 0.74894328| Val Acc: 0.74966482\n",
            "best epoch 94\n",
            "Epoch 094: | Train Loss: 0.73412258 | Val Loss: 0.73238358 | Train Acc: 0.74897204| Val Acc: 0.74970721\n",
            "best epoch 95\n",
            "Epoch 095: | Train Loss: 0.73407393 | Val Loss: 0.73233235 | Train Acc: 0.74898113| Val Acc: 0.74971932\n",
            "best epoch 96\n",
            "Epoch 096: | Train Loss: 0.73402607 | Val Loss: 0.73228199 | Train Acc: 0.74897356| Val Acc: 0.74973749\n",
            "best epoch 97\n",
            "Epoch 097: | Train Loss: 0.73397901 | Val Loss: 0.73223247 | Train Acc: 0.74898415| Val Acc: 0.74975565\n",
            "best epoch 98\n",
            "Epoch 098: | Train Loss: 0.73393271 | Val Loss: 0.73218377 | Train Acc: 0.74899929| Val Acc: 0.74980409\n",
            "best epoch 99\n",
            "Epoch 099: | Train Loss: 0.73388714 | Val Loss: 0.73213583 | Train Acc: 0.74901746| Val Acc: 0.74981620\n",
            "best epoch 100\n",
            "Epoch 100: | Train Loss: 0.73384229 | Val Loss: 0.73208872 | Train Acc: 0.74903865| Val Acc: 0.74984042\n",
            "best epoch 101\n",
            "Epoch 101: | Train Loss: 0.73379816 | Val Loss: 0.73204235 | Train Acc: 0.74907649| Val Acc: 0.74984648\n",
            "best epoch 102\n",
            "Epoch 102: | Train Loss: 0.73375470 | Val Loss: 0.73199668 | Train Acc: 0.74909466| Val Acc: 0.74986464\n",
            "best epoch 103\n",
            "Epoch 103: | Train Loss: 0.73371190 | Val Loss: 0.73195169 | Train Acc: 0.74910677| Val Acc: 0.74988886\n",
            "best epoch 104\n",
            "Epoch 104: | Train Loss: 0.73366976 | Val Loss: 0.73190738 | Train Acc: 0.74911888| Val Acc: 0.74988886\n",
            "best epoch 105\n",
            "Epoch 105: | Train Loss: 0.73362826 | Val Loss: 0.73186372 | Train Acc: 0.74912342| Val Acc: 0.74987070\n",
            "best epoch 106\n",
            "Epoch 106: | Train Loss: 0.73358738 | Val Loss: 0.73182074 | Train Acc: 0.74913856| Val Acc: 0.74986464\n",
            "best epoch 107\n",
            "Epoch 107: | Train Loss: 0.73354712 | Val Loss: 0.73177845 | Train Acc: 0.74914310| Val Acc: 0.74988281\n",
            "best epoch 108\n",
            "Epoch 108: | Train Loss: 0.73350745 | Val Loss: 0.73173682 | Train Acc: 0.74916580| Val Acc: 0.74989492\n",
            "best epoch 109\n",
            "Epoch 109: | Train Loss: 0.73346831 | Val Loss: 0.73169573 | Train Acc: 0.74916883| Val Acc: 0.74988886\n",
            "best epoch 110\n",
            "Epoch 110: | Train Loss: 0.73342975 | Val Loss: 0.73165527 | Train Acc: 0.74918397| Val Acc: 0.74991308\n",
            "best epoch 111\n",
            "Epoch 111: | Train Loss: 0.73339173 | Val Loss: 0.73161542 | Train Acc: 0.74919759| Val Acc: 0.74993125\n",
            "best epoch 112\n",
            "Epoch 112: | Train Loss: 0.73335427 | Val Loss: 0.73157607 | Train Acc: 0.74921727| Val Acc: 0.74996152\n",
            "best epoch 113\n",
            "Epoch 113: | Train Loss: 0.73331734 | Val Loss: 0.73153732 | Train Acc: 0.74923089| Val Acc: 0.74997363\n",
            "best epoch 114\n",
            "Epoch 114: | Train Loss: 0.73328091 | Val Loss: 0.73149905 | Train Acc: 0.74924906| Val Acc: 0.75000391\n",
            "best epoch 115\n",
            "Epoch 115: | Train Loss: 0.73324498 | Val Loss: 0.73146141 | Train Acc: 0.74927177| Val Acc: 0.75000391\n",
            "best epoch 116\n",
            "Epoch 116: | Train Loss: 0.73320954 | Val Loss: 0.73142417 | Train Acc: 0.74927328| Val Acc: 0.75000391\n",
            "best epoch 117\n",
            "Epoch 117: | Train Loss: 0.73317458 | Val Loss: 0.73138740 | Train Acc: 0.74928690| Val Acc: 0.74999180\n",
            "best epoch 118\n",
            "Epoch 118: | Train Loss: 0.73314010 | Val Loss: 0.73135131 | Train Acc: 0.74930204| Val Acc: 0.74996758\n",
            "best epoch 119\n",
            "Epoch 119: | Train Loss: 0.73310608 | Val Loss: 0.73131560 | Train Acc: 0.74930507| Val Acc: 0.74996152\n",
            "best epoch 120\n",
            "Epoch 120: | Train Loss: 0.73307251 | Val Loss: 0.73128044 | Train Acc: 0.74930053| Val Acc: 0.74995547\n",
            "best epoch 121\n",
            "Epoch 121: | Train Loss: 0.73303936 | Val Loss: 0.73124566 | Train Acc: 0.74931415| Val Acc: 0.74999180\n",
            "best epoch 122\n",
            "Epoch 122: | Train Loss: 0.73300666 | Val Loss: 0.73121138 | Train Acc: 0.74932172| Val Acc: 0.74999180\n",
            "best epoch 123\n",
            "Epoch 123: | Train Loss: 0.73297437 | Val Loss: 0.73117750 | Train Acc: 0.74932021| Val Acc: 0.75001602\n",
            "best epoch 124\n",
            "Epoch 124: | Train Loss: 0.73294248 | Val Loss: 0.73114407 | Train Acc: 0.74933686| Val Acc: 0.75005840\n",
            "best epoch 125\n",
            "Epoch 125: | Train Loss: 0.73291104 | Val Loss: 0.73111111 | Train Acc: 0.74934897| Val Acc: 0.75007657\n",
            "best epoch 126\n",
            "Epoch 126: | Train Loss: 0.73287999 | Val Loss: 0.73107853 | Train Acc: 0.74936259| Val Acc: 0.75008868\n",
            "best epoch 127\n",
            "Epoch 127: | Train Loss: 0.73284931 | Val Loss: 0.73104637 | Train Acc: 0.74937167| Val Acc: 0.75011895\n",
            "best epoch 128\n",
            "Epoch 128: | Train Loss: 0.73281900 | Val Loss: 0.73101460 | Train Acc: 0.74937773| Val Acc: 0.75011895\n",
            "best epoch 129\n",
            "Epoch 129: | Train Loss: 0.73278905 | Val Loss: 0.73098322 | Train Acc: 0.74938076| Val Acc: 0.75010079\n",
            "best epoch 130\n",
            "Epoch 130: | Train Loss: 0.73275948 | Val Loss: 0.73095220 | Train Acc: 0.74938984| Val Acc: 0.75008868\n",
            "best epoch 131\n",
            "Epoch 131: | Train Loss: 0.73273027 | Val Loss: 0.73092159 | Train Acc: 0.74939741| Val Acc: 0.75011290\n",
            "best epoch 132\n",
            "Epoch 132: | Train Loss: 0.73270140 | Val Loss: 0.73089130 | Train Acc: 0.74941103| Val Acc: 0.75011895\n",
            "best epoch 133\n",
            "Epoch 133: | Train Loss: 0.73267287 | Val Loss: 0.73086137 | Train Acc: 0.74942466| Val Acc: 0.75014317\n",
            "best epoch 134\n",
            "Epoch 134: | Train Loss: 0.73264468 | Val Loss: 0.73083186 | Train Acc: 0.74943979| Val Acc: 0.75015528\n",
            "best epoch 135\n",
            "Epoch 135: | Train Loss: 0.73261682 | Val Loss: 0.73080261 | Train Acc: 0.74945190| Val Acc: 0.75015528\n",
            "best epoch 136\n",
            "Epoch 136: | Train Loss: 0.73258929 | Val Loss: 0.73077375 | Train Acc: 0.74947915| Val Acc: 0.75016739\n",
            "best epoch 137\n",
            "Epoch 137: | Train Loss: 0.73256207 | Val Loss: 0.73074530 | Train Acc: 0.74948521| Val Acc: 0.75016739\n",
            "best epoch 138\n",
            "Epoch 138: | Train Loss: 0.73253517 | Val Loss: 0.73071717 | Train Acc: 0.74948823| Val Acc: 0.75019767\n",
            "best epoch 139\n",
            "Epoch 139: | Train Loss: 0.73250856 | Val Loss: 0.73068931 | Train Acc: 0.74950186| Val Acc: 0.75019767\n",
            "best epoch 140\n",
            "Epoch 140: | Train Loss: 0.73248227 | Val Loss: 0.73066176 | Train Acc: 0.74951245| Val Acc: 0.75027033\n",
            "best epoch 141\n",
            "Epoch 141: | Train Loss: 0.73245626 | Val Loss: 0.73063454 | Train Acc: 0.74952608| Val Acc: 0.75028244\n",
            "best epoch 142\n",
            "Epoch 142: | Train Loss: 0.73243056 | Val Loss: 0.73060767 | Train Acc: 0.74953667| Val Acc: 0.75028244\n",
            "best epoch 143\n",
            "Epoch 143: | Train Loss: 0.73240513 | Val Loss: 0.73058099 | Train Acc: 0.74954424| Val Acc: 0.75025822\n",
            "best epoch 144\n",
            "Epoch 144: | Train Loss: 0.73237998 | Val Loss: 0.73055473 | Train Acc: 0.74955333| Val Acc: 0.75027033\n",
            "best epoch 145\n",
            "Epoch 145: | Train Loss: 0.73235512 | Val Loss: 0.73052866 | Train Acc: 0.74956241| Val Acc: 0.75026427\n",
            "best epoch 146\n",
            "Epoch 146: | Train Loss: 0.73233052 | Val Loss: 0.73050292 | Train Acc: 0.74956089| Val Acc: 0.75028244\n",
            "best epoch 147\n",
            "Epoch 147: | Train Loss: 0.73230620 | Val Loss: 0.73047744 | Train Acc: 0.74957452| Val Acc: 0.75034299\n",
            "best epoch 148\n",
            "Epoch 148: | Train Loss: 0.73228212 | Val Loss: 0.73045222 | Train Acc: 0.74957149| Val Acc: 0.75034299\n",
            "best epoch 149\n",
            "Epoch 149: | Train Loss: 0.73225830 | Val Loss: 0.73042725 | Train Acc: 0.74956544| Val Acc: 0.75033088\n",
            "best epoch 150\n",
            "Epoch 150: | Train Loss: 0.73223473 | Val Loss: 0.73040264 | Train Acc: 0.74956846| Val Acc: 0.75034904\n",
            "best epoch 151\n",
            "Epoch 151: | Train Loss: 0.73221140 | Val Loss: 0.73037814 | Train Acc: 0.74957452| Val Acc: 0.75033693\n",
            "best epoch 152\n",
            "Epoch 152: | Train Loss: 0.73218834 | Val Loss: 0.73035400 | Train Acc: 0.74958966| Val Acc: 0.75033693\n",
            "best epoch 153\n",
            "Epoch 153: | Train Loss: 0.73216551 | Val Loss: 0.73033016 | Train Acc: 0.74959420| Val Acc: 0.75034904\n",
            "best epoch 154\n",
            "Epoch 154: | Train Loss: 0.73214294 | Val Loss: 0.73030654 | Train Acc: 0.74960025| Val Acc: 0.75034904\n",
            "best epoch 155\n",
            "Epoch 155: | Train Loss: 0.73212058 | Val Loss: 0.73028315 | Train Acc: 0.74960782| Val Acc: 0.75036721\n",
            "best epoch 156\n",
            "Epoch 156: | Train Loss: 0.73209844 | Val Loss: 0.73025997 | Train Acc: 0.74961388| Val Acc: 0.75036115\n",
            "best epoch 157\n",
            "Epoch 157: | Train Loss: 0.73207652 | Val Loss: 0.73023699 | Train Acc: 0.74962750| Val Acc: 0.75037326\n",
            "best epoch 158\n",
            "Epoch 158: | Train Loss: 0.73205483 | Val Loss: 0.73021431 | Train Acc: 0.74963507| Val Acc: 0.75036721\n",
            "best epoch 159\n",
            "Epoch 159: | Train Loss: 0.73203335 | Val Loss: 0.73019181 | Train Acc: 0.74963658| Val Acc: 0.75035510\n",
            "best epoch 160\n",
            "Epoch 160: | Train Loss: 0.73201209 | Val Loss: 0.73016953 | Train Acc: 0.74963961| Val Acc: 0.75034299\n",
            "best epoch 161\n",
            "Epoch 161: | Train Loss: 0.73199103 | Val Loss: 0.73014755 | Train Acc: 0.74964718| Val Acc: 0.75036115\n",
            "best epoch 162\n",
            "Epoch 162: | Train Loss: 0.73197016 | Val Loss: 0.73012571 | Train Acc: 0.74963961| Val Acc: 0.75036721\n",
            "best epoch 163\n",
            "Epoch 163: | Train Loss: 0.73194950 | Val Loss: 0.73010406 | Train Acc: 0.74963204| Val Acc: 0.75039748\n",
            "best epoch 164\n",
            "Epoch 164: | Train Loss: 0.73192906 | Val Loss: 0.73008262 | Train Acc: 0.74964869| Val Acc: 0.75039748\n",
            "best epoch 165\n",
            "Epoch 165: | Train Loss: 0.73190881 | Val Loss: 0.73006146 | Train Acc: 0.74966383| Val Acc: 0.75041565\n",
            "best epoch 166\n",
            "Epoch 166: | Train Loss: 0.73188875 | Val Loss: 0.73004044 | Train Acc: 0.74967745| Val Acc: 0.75042776\n",
            "best epoch 167\n",
            "Epoch 167: | Train Loss: 0.73186887 | Val Loss: 0.73001960 | Train Acc: 0.74968351| Val Acc: 0.75040959\n",
            "best epoch 168\n",
            "Epoch 168: | Train Loss: 0.73184917 | Val Loss: 0.72999903 | Train Acc: 0.74968956| Val Acc: 0.75040354\n",
            "best epoch 169\n",
            "Epoch 169: | Train Loss: 0.73182966 | Val Loss: 0.72997863 | Train Acc: 0.74970167| Val Acc: 0.75039748\n",
            "best epoch 170\n",
            "Epoch 170: | Train Loss: 0.73181035 | Val Loss: 0.72995845 | Train Acc: 0.74970773| Val Acc: 0.75040959\n",
            "best epoch 171\n",
            "Epoch 171: | Train Loss: 0.73179123 | Val Loss: 0.72993844 | Train Acc: 0.74971681| Val Acc: 0.75039143\n",
            "best epoch 172\n",
            "Epoch 172: | Train Loss: 0.73177227 | Val Loss: 0.72991861 | Train Acc: 0.74971832| Val Acc: 0.75041565\n",
            "best epoch 173\n",
            "Epoch 173: | Train Loss: 0.73175347 | Val Loss: 0.72989896 | Train Acc: 0.74972589| Val Acc: 0.75042170\n",
            "best epoch 174\n",
            "Epoch 174: | Train Loss: 0.73173485 | Val Loss: 0.72987954 | Train Acc: 0.74973649| Val Acc: 0.75044592\n",
            "best epoch 175\n",
            "Epoch 175: | Train Loss: 0.73171642 | Val Loss: 0.72986021 | Train Acc: 0.74973649| Val Acc: 0.75044592\n",
            "best epoch 176\n",
            "Epoch 176: | Train Loss: 0.73169813 | Val Loss: 0.72984111 | Train Acc: 0.74975011| Val Acc: 0.75045198\n",
            "best epoch 177\n",
            "Epoch 177: | Train Loss: 0.73168001 | Val Loss: 0.72982218 | Train Acc: 0.74976071| Val Acc: 0.75046409\n",
            "best epoch 178\n",
            "Epoch 178: | Train Loss: 0.73166205 | Val Loss: 0.72980338 | Train Acc: 0.74976676| Val Acc: 0.75048225\n",
            "best epoch 179\n",
            "Epoch 179: | Train Loss: 0.73164425 | Val Loss: 0.72978475 | Train Acc: 0.74977433| Val Acc: 0.75048831\n",
            "best epoch 180\n",
            "Epoch 180: | Train Loss: 0.73162660 | Val Loss: 0.72976629 | Train Acc: 0.74977736| Val Acc: 0.75048225\n",
            "best epoch 181\n",
            "Epoch 181: | Train Loss: 0.73160910 | Val Loss: 0.72974797 | Train Acc: 0.74977736| Val Acc: 0.75050042\n",
            "best epoch 182\n",
            "Epoch 182: | Train Loss: 0.73159174 | Val Loss: 0.72972980 | Train Acc: 0.74979250| Val Acc: 0.75050647\n",
            "best epoch 183\n",
            "Epoch 183: | Train Loss: 0.73157452 | Val Loss: 0.72971180 | Train Acc: 0.74980461| Val Acc: 0.75051253\n",
            "best epoch 184\n",
            "Epoch 184: | Train Loss: 0.73155746 | Val Loss: 0.72969397 | Train Acc: 0.74981369| Val Acc: 0.75051858\n",
            "best epoch 185\n",
            "Epoch 185: | Train Loss: 0.73154055 | Val Loss: 0.72967626 | Train Acc: 0.74981823| Val Acc: 0.75056702\n",
            "best epoch 186\n",
            "Epoch 186: | Train Loss: 0.73152378 | Val Loss: 0.72965872 | Train Acc: 0.74981521| Val Acc: 0.75057913\n",
            "best epoch 187\n",
            "Epoch 187: | Train Loss: 0.73150716 | Val Loss: 0.72964130 | Train Acc: 0.74980764| Val Acc: 0.75057913\n",
            "best epoch 188\n",
            "Epoch 188: | Train Loss: 0.73149067 | Val Loss: 0.72962404 | Train Acc: 0.74981672| Val Acc: 0.75061546\n",
            "best epoch 189\n",
            "Epoch 189: | Train Loss: 0.73147432 | Val Loss: 0.72960698 | Train Acc: 0.74982883| Val Acc: 0.75062152\n",
            "best epoch 190\n",
            "Epoch 190: | Train Loss: 0.73145811 | Val Loss: 0.72959004 | Train Acc: 0.74983337| Val Acc: 0.75062757\n",
            "best epoch 191\n",
            "Epoch 191: | Train Loss: 0.73144204 | Val Loss: 0.72957327 | Train Acc: 0.74984397| Val Acc: 0.75063363\n",
            "best epoch 192\n",
            "Epoch 192: | Train Loss: 0.73142610 | Val Loss: 0.72955660 | Train Acc: 0.74985305| Val Acc: 0.75065179\n",
            "best epoch 193\n",
            "Epoch 193: | Train Loss: 0.73141029 | Val Loss: 0.72954012 | Train Acc: 0.74985002| Val Acc: 0.75065785\n",
            "best epoch 194\n",
            "Epoch 194: | Train Loss: 0.73139462 | Val Loss: 0.72952359 | Train Acc: 0.74987121| Val Acc: 0.75065785\n",
            "best epoch 195\n",
            "Epoch 195: | Train Loss: 0.73137907 | Val Loss: 0.72950730 | Train Acc: 0.74988030| Val Acc: 0.75065785\n",
            "best epoch 196\n",
            "Epoch 196: | Train Loss: 0.73136365 | Val Loss: 0.72949115 | Train Acc: 0.74988787| Val Acc: 0.75070023\n",
            "best epoch 197\n",
            "Epoch 197: | Train Loss: 0.73134835 | Val Loss: 0.72947516 | Train Acc: 0.74989846| Val Acc: 0.75073656\n",
            "best epoch 198\n",
            "Epoch 198: | Train Loss: 0.73133317 | Val Loss: 0.72945933 | Train Acc: 0.74989695| Val Acc: 0.75074262\n",
            "best epoch 199\n",
            "Epoch 199: | Train Loss: 0.73131812 | Val Loss: 0.72944358 | Train Acc: 0.74990906| Val Acc: 0.75073051\n",
            "best epoch 200\n",
            "Epoch 200: | Train Loss: 0.73130319 | Val Loss: 0.72942798 | Train Acc: 0.74991360| Val Acc: 0.75071840\n",
            "\n",
            "Model - Post-training AnfisNet(\n",
            "  Rule  0: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.5290165543556213], [0.3345181941986084], [0.35011738538742065], [0.0], [0.6127059459686279], [1.0]]\n",
            "  Rule  1: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.6882725954055786], [0.6336729526519775], [0.583815336227417], [1.0], [0.23666995763778687], [0.0]]\n",
            "  Rule  2: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.9515730142593384], [1.0], [0.1253337860107422], [0.0], [0.3141361176967621], [0.10822063684463501]]\n",
            "  Rule  3: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.008325397968292236], [0.8799264430999756], [0.0], [0.26500436663627625], [0.9924623370170593]]\n",
            "  Rule  4: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.24137496948242188], [0.4353727698326111], [1.0], [0.532317042350769], [0.69915771484375]]\n",
            "  Rule  5: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.5815953016281128], [0.7070150375366211], [0.5303930640220642], [1.0], [0.38586363196372986]]\n",
            "  Rule  6: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.5491044521331787], [0.7918579578399658], [0.5858147740364075], [1.0], [0.0], [0.863813042640686]]\n",
            "  Rule  7: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.9999999403953552], [0.3773840665817261], [0.7355440855026245], [0.08545568585395813], [0.5157030820846558]]\n",
            "  Rule  8: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.9973500370979309], [0.9613404273986816], [1.0], [0.9615275859832764], [0.8868745565414429], [0.0]]\n",
            "  Rule  9: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.7608098387718201], [0.336209237575531], [0.0], [0.4282425343990326], [0.4484960734844208], [1.0]]\n",
            "  Rule 10: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[1.0], [0.6353687644004822], [0.5605428814888], [0.0], [0.38430696725845337], [0.715445876121521]]\n",
            "  Rule 11: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.5639640688896179], [0.7027133107185364], [0.8428123593330383], [0.6339484453201294], [0.0]]\n",
            "  Rule 12: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.38614240288734436], [0.46503692865371704], [0.8782370686531067], [0.7424644231796265], [0.9999999403953552]]\n",
            "  Rule 13: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.9984713792800903], [1.0000001192092896], [0.24379640817642212], [0.9756721258163452], [0.9115881323814392]]\n",
            "  Rule 14: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[1.0], [0.9273225665092468], [0.9276937246322632], [0.5440942645072937], [0.7010453939437866], [0.0]]\n",
            "  Rule 15: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.902816891670227], [0.30513715744018555], [0.6541086435317993], [1.0], [0.5103803873062134], [0.0]]\n",
            "  (layer): ModuleDict(\n",
            "    (fuzzify): Input variables\n",
            "    Variable x0\n",
            "    - mf0: GaussMembFunc(mu=-95.9389419555664, sigma=79.70187377929688)\n",
            "    - mf1: GaussMembFunc(mu=200.32147216796875, sigma=107.41265106201172)\n",
            "    Variable x1\n",
            "    - mf0: GaussMembFunc(mu=-64.37088775634766, sigma=93.11461639404297)\n",
            "    - mf1: GaussMembFunc(mu=234.87100219726562, sigma=114.1301498413086)\n",
            "    Variable x2\n",
            "    - mf0: GaussMembFunc(mu=-78.53134155273438, sigma=126.8692855834961)\n",
            "    - mf1: GaussMembFunc(mu=214.76739501953125, sigma=102.93939971923828)\n",
            "    Variable x3\n",
            "    - mf0: GaussMembFunc(mu=0.4149702787399292, sigma=2.090277671813965)\n",
            "    - mf1: GaussMembFunc(mu=5.099608421325684, sigma=1.3243193626403809)\n",
            "    (rules): AntecedentLayer()\n",
            "    (consequent): PlainConsequentLayer()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RISULTATI TEST\n",
            "265360 of 353895 correct (accuracy=74.98%)\n",
            "tensor([5, 3, 1,  ..., 1, 3, 2])\n",
            "[[56634  3387  4407  3304   483    41]\n",
            " [ 6130 19420  4345  8471  2430   840]\n",
            " [ 5385  4974 47306  6204  1149   668]\n",
            " [ 6422  5069  1787 71608  4358  1735]\n",
            " [  812   334  5535  3886 28000    86]\n",
            " [  103   827    30  5264    69 42392]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79     68256\n",
            "         1.0       0.57      0.47      0.51     41636\n",
            "         2.0       0.75      0.72      0.73     65686\n",
            "         3.0       0.73      0.79      0.75     90979\n",
            "         4.0       0.77      0.72      0.75     38653\n",
            "         5.0       0.93      0.87      0.90     48685\n",
            "\n",
            "    accuracy                           0.75    353895\n",
            "   macro avg       0.75      0.73      0.74    353895\n",
            "weighted avg       0.75      0.75      0.75    353895\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtwrSEkPek74"
      },
      "source": [
        "# Test 2\n",
        "\n",
        "In the following test I choose to configure the ANFIS training with:\n",
        "\n",
        "\n",
        "*   Nr. 3 Fuzzy Sets\n",
        "*   32 of Batch size\n",
        "*   Nr. 100 of epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5db64db0ddcd490896165bf494b4948e",
            "f039b94c1fd3436bbd7ea0921e597e39",
            "dc8250a626bb4104bd1d68f0f7c16571",
            "bdd4c9711b54497899e34b9c588938d6",
            "b0ea6c66e68643409f2adc8912886133",
            "311bec319b204ec8b36b9fd9abaf0019",
            "2cc7e2add88f43c287e343aeeec62e4a",
            "7d71b47e4ee9449d98398fff0804ceae"
          ]
        },
        "id": "RZZjef84esld",
        "outputId": "9267f675-bc8a-426d-d636-637e55456dbc"
      },
      "source": [
        "dataset = 'datasets/reducedTopClass/reducedTC.csv'\n",
        "model = None\n",
        "n_terms = 3 #IMPOSTA NUMERO DI FUZZY SET\n",
        "batch_size = 32\n",
        "num_categories = 6 #IMPOSTA NUMERO DI CLASSI\n",
        "epoch = 200\n",
        "model_l = False #SEMPRE A FALSE\n",
        "hybrid = False #SEMPRE A FALSE\n",
        "i = 0\n",
        "lista_acc = []\n",
        "k_fold = False\n",
        "\n",
        "# Make the classes available via (controlled) reflection:\n",
        "get_class_for = {n: globals()[n]\n",
        "                 for n in ['BellMembFunc',\n",
        "                           'GaussMembFunc',\n",
        "                           'TriangularMembFunc',\n",
        "                           'TrapezoidalMembFunc',\n",
        "                           ]}\n",
        "\n",
        "# DEFINIRE LA MEMBERSHIP FUNCTION ATTUALMENTE E' ABILITATA SOLO GAUSSIANA E TRIANGOLARE\n",
        "membership_function = get_class_for['GaussMembFunc']\n",
        "\n",
        "d_data, d_target = split_dataset(dataset)\n",
        "\n",
        "\n",
        "# Split train into trainval-test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(d_data, d_target, test_size=0.3, shuffle=True,\n",
        "                                                          stratify=d_target, random_state=42)\n",
        "\n",
        "# Split train into train-val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, shuffle=True,\n",
        "                                               stratify=y_trainval, random_state=42)\n",
        "\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val, n_terms, num_categories,\n",
        "                                   batch_size, epoch, model_l, hybrid, membership_function, i)\n",
        "\n",
        "torch.save(model, 'models/G_model_geo_' + str(3) + 'topClass' + '.h5')\n",
        "\n",
        "model = torch.load('models/G_model_geo_3topClass.h5')\n",
        "\n",
        "test_model(model, X_test, y_test, num_categories, k_fold, i, lista_acc)\n",
        "\n",
        "model = torch.load('models/G_model_geo_3topClass.h5')\n",
        "\n",
        "X_test = torch.Tensor(X_test)\n",
        "\n",
        "y_pred = model(X_test)\n",
        "\n",
        "cat_act = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "#PREDIZIONE SUI DATI DI TEST\n",
        "print(cat_act)\n",
        "\n",
        "cm = confusion_matrix(y_test, cat_act)\n",
        "print(cm)\n",
        "\n",
        "cl = classification_report(y_test, cat_act)\n",
        "print(cl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Model - Pre-training\n",
            "AnfisNet(\n",
            "  Rule  0: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  1: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  2: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  3: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  4: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  5: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  6: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  7: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  8: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  9: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 10: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 11: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 12: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 13: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 14: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 15: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 16: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 17: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 18: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 19: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 20: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 21: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 22: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 23: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 24: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 25: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 26: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 27: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 28: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 29: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 30: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 31: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 32: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 33: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 34: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 35: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 36: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 37: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 38: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 39: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 40: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 41: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 42: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 43: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 44: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 45: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 46: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 47: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 48: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 49: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 50: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 51: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 52: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 53: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 54: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 55: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 56: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 57: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 58: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 59: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 60: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 61: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 62: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 63: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 64: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 65: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 66: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 67: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 68: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 69: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 70: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 71: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 72: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 73: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 74: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 75: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 76: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 77: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 78: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 79: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 80: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  (layer): ModuleDict(\n",
            "    (fuzzify): Input variables\n",
            "    Variable x0\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=83.33333587646484)\n",
            "    - mf1: GaussMembFunc(mu=125.0, sigma=83.33333587646484)\n",
            "    - mf2: GaussMembFunc(mu=250.0, sigma=83.33333587646484)\n",
            "    Variable x1\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=85.0)\n",
            "    - mf1: GaussMembFunc(mu=127.5, sigma=85.0)\n",
            "    - mf2: GaussMembFunc(mu=255.0, sigma=85.0)\n",
            "    Variable x2\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=85.0)\n",
            "    - mf1: GaussMembFunc(mu=127.5, sigma=85.0)\n",
            "    - mf2: GaussMembFunc(mu=255.0, sigma=85.0)\n",
            "    Variable x3\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=1.6193270683288574)\n",
            "    - mf1: GaussMembFunc(mu=2.428990602493286, sigma=1.6193270683288574)\n",
            "    - mf2: GaussMembFunc(mu=4.857981204986572, sigma=1.6193270683288574)\n",
            "    (rules): AntecedentLayer()\n",
            "    (consequent): PlainConsequentLayer()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5db64db0ddcd490896165bf494b4948e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best epoch 1\n",
            "Epoch 001: | Train Loss: 0.85740887 | Val Loss: 0.76957052 | Train Acc: 0.70215119| Val Acc: 0.73397625\n",
            "best epoch 2\n",
            "Epoch 002: | Train Loss: 0.75375387 | Val Loss: 0.74263422 | Train Acc: 0.73865125| Val Acc: 0.74267732\n",
            "best epoch 3\n",
            "Epoch 003: | Train Loss: 0.73565670 | Val Loss: 0.72967667 | Train Acc: 0.74486673| Val Acc: 0.74669181\n",
            "best epoch 4\n",
            "Epoch 004: | Train Loss: 0.72541886 | Val Loss: 0.72157226 | Train Acc: 0.74843349| Val Acc: 0.74927125\n",
            "best epoch 5\n",
            "Epoch 005: | Train Loss: 0.71899963 | Val Loss: 0.71624643 | Train Acc: 0.75050280| Val Acc: 0.75111823\n",
            "best epoch 6\n",
            "Epoch 006: | Train Loss: 0.71464622 | Val Loss: 0.71241700 | Train Acc: 0.75192876| Val Acc: 0.75268648\n",
            "best epoch 7\n",
            "Epoch 007: | Train Loss: 0.71140441 | Val Loss: 0.70947547 | Train Acc: 0.75301412| Val Acc: 0.75388537\n",
            "best epoch 8\n",
            "Epoch 008: | Train Loss: 0.70884961 | Val Loss: 0.70712546 | Train Acc: 0.75381187| Val Acc: 0.75484207\n",
            "best epoch 9\n",
            "Epoch 009: | Train Loss: 0.70677809 | Val Loss: 0.70519529 | Train Acc: 0.75449004| Val Acc: 0.75565344\n",
            "best epoch 10\n",
            "Epoch 010: | Train Loss: 0.70506059 | Val Loss: 0.70356529 | Train Acc: 0.75515760| Val Acc: 0.75626500\n",
            "best epoch 11\n",
            "Epoch 011: | Train Loss: 0.70359894 | Val Loss: 0.70215882 | Train Acc: 0.75570104| Val Acc: 0.75680390\n",
            "best epoch 12\n",
            "Epoch 012: | Train Loss: 0.70233024 | Val Loss: 0.70092517 | Train Acc: 0.75616274| Val Acc: 0.75714903\n",
            "best epoch 13\n",
            "Epoch 013: | Train Loss: 0.70121275 | Val Loss: 0.69982853 | Train Acc: 0.75653512| Val Acc: 0.75754261\n",
            "best epoch 14\n",
            "Epoch 014: | Train Loss: 0.70021619 | Val Loss: 0.69884221 | Train Acc: 0.75683939| Val Acc: 0.75784536\n",
            "best epoch 15\n",
            "Epoch 015: | Train Loss: 0.69931765 | Val Loss: 0.69794691 | Train Acc: 0.75718452| Val Acc: 0.75832371\n",
            "best epoch 16\n",
            "Epoch 016: | Train Loss: 0.69849945 | Val Loss: 0.69712703 | Train Acc: 0.75751604| Val Acc: 0.75880206\n",
            "best epoch 17\n",
            "Epoch 017: | Train Loss: 0.69774769 | Val Loss: 0.69637064 | Train Acc: 0.75769315| Val Acc: 0.75908664\n",
            "best epoch 18\n",
            "Epoch 018: | Train Loss: 0.69705126 | Val Loss: 0.69566799 | Train Acc: 0.75791113| Val Acc: 0.75926224\n",
            "best epoch 19\n",
            "Epoch 019: | Train Loss: 0.69640129 | Val Loss: 0.69501114 | Train Acc: 0.75808672| Val Acc: 0.75945620\n",
            "best epoch 20\n",
            "Epoch 020: | Train Loss: 0.69579063 | Val Loss: 0.69439376 | Train Acc: 0.75828351| Val Acc: 0.75966207\n",
            "best epoch 21\n",
            "Epoch 021: | Train Loss: 0.69521353 | Val Loss: 0.69381003 | Train Acc: 0.75843791| Val Acc: 0.75992243\n",
            "best epoch 22\n",
            "Epoch 022: | Train Loss: 0.69466516 | Val Loss: 0.69325567 | Train Acc: 0.75863924| Val Acc: 0.76011014\n",
            "best epoch 23\n",
            "Epoch 023: | Train Loss: 0.69414162 | Val Loss: 0.69272682 | Train Acc: 0.75874975| Val Acc: 0.76029784\n",
            "best epoch 24\n",
            "Epoch 024: | Train Loss: 0.69363972 | Val Loss: 0.69222017 | Train Acc: 0.75889658| Val Acc: 0.76054005\n",
            "best epoch 25\n",
            "Epoch 025: | Train Loss: 0.69315672 | Val Loss: 0.69173311 | Train Acc: 0.75901011| Val Acc: 0.76059454\n",
            "best epoch 26\n",
            "Epoch 026: | Train Loss: 0.69269032 | Val Loss: 0.69126307 | Train Acc: 0.75910851| Val Acc: 0.76079436\n",
            "best epoch 27\n",
            "Epoch 027: | Train Loss: 0.69223868 | Val Loss: 0.69080820 | Train Acc: 0.75917511| Val Acc: 0.76098206\n",
            "best epoch 28\n",
            "Epoch 028: | Train Loss: 0.69180013 | Val Loss: 0.69036662 | Train Acc: 0.75931287| Val Acc: 0.76106683\n",
            "best epoch 29\n",
            "Epoch 029: | Train Loss: 0.69137339 | Val Loss: 0.68993701 | Train Acc: 0.75943397| Val Acc: 0.76124243\n",
            "best epoch 30\n",
            "Epoch 030: | Train Loss: 0.69095732 | Val Loss: 0.68951792 | Train Acc: 0.75950965| Val Acc: 0.76132114\n",
            "best epoch 31\n",
            "Epoch 031: | Train Loss: 0.69055092 | Val Loss: 0.68910838 | Train Acc: 0.75960048| Val Acc: 0.76144225\n",
            "best epoch 32\n",
            "Epoch 032: | Train Loss: 0.69015341 | Val Loss: 0.68870724 | Train Acc: 0.75971250| Val Acc: 0.76163601\n",
            "best epoch 33\n",
            "Epoch 033: | Train Loss: 0.68976395 | Val Loss: 0.68831388 | Train Acc: 0.75981695| Val Acc: 0.76178133\n",
            "best epoch 34\n",
            "Epoch 034: | Train Loss: 0.68938186 | Val Loss: 0.68792754 | Train Acc: 0.75989566| Val Acc: 0.76185399\n",
            "best epoch 35\n",
            "Epoch 035: | Train Loss: 0.68900660 | Val Loss: 0.68754766 | Train Acc: 0.75997286| Val Acc: 0.76199931\n",
            "best epoch 36\n",
            "Epoch 036: | Train Loss: 0.68863769 | Val Loss: 0.68717407 | Train Acc: 0.76005309| Val Acc: 0.76207197\n",
            "best epoch 37\n",
            "Epoch 037: | Train Loss: 0.68827473 | Val Loss: 0.68680637 | Train Acc: 0.76015452| Val Acc: 0.76210830\n",
            "best epoch 38\n",
            "Epoch 038: | Train Loss: 0.68791745 | Val Loss: 0.68644433 | Train Acc: 0.76025896| Val Acc: 0.76216279\n",
            "best epoch 39\n",
            "Epoch 039: | Train Loss: 0.68756584 | Val Loss: 0.68608807 | Train Acc: 0.76034828| Val Acc: 0.76225967\n",
            "best epoch 40\n",
            "Epoch 040: | Train Loss: 0.68721998 | Val Loss: 0.68573765 | Train Acc: 0.76044970| Val Acc: 0.76225967\n",
            "best epoch 41\n",
            "Epoch 041: | Train Loss: 0.68688027 | Val Loss: 0.68539356 | Train Acc: 0.76051176| Val Acc: 0.76235050\n",
            "best epoch 42\n",
            "Epoch 042: | Train Loss: 0.68654726 | Val Loss: 0.68505622 | Train Acc: 0.76056928| Val Acc: 0.76251399\n",
            "best epoch 43\n",
            "Epoch 043: | Train Loss: 0.68622166 | Val Loss: 0.68472623 | Train Acc: 0.76066616| Val Acc: 0.76261692\n",
            "best epoch 44\n",
            "Epoch 044: | Train Loss: 0.68590416 | Val Loss: 0.68440440 | Train Acc: 0.76071461| Val Acc: 0.76267747\n",
            "best epoch 45\n",
            "Epoch 045: | Train Loss: 0.68559521 | Val Loss: 0.68409073 | Train Acc: 0.76075548| Val Acc: 0.76274408\n",
            "best epoch 46\n",
            "Epoch 046: | Train Loss: 0.68529487 | Val Loss: 0.68378570 | Train Acc: 0.76085084| Val Acc: 0.76283490\n",
            "best epoch 47\n",
            "Epoch 047: | Train Loss: 0.68500291 | Val Loss: 0.68348880 | Train Acc: 0.76094772| Val Acc: 0.76300444\n",
            "best epoch 48\n",
            "Epoch 048: | Train Loss: 0.68471892 | Val Loss: 0.68319953 | Train Acc: 0.76104612| Val Acc: 0.76305288\n",
            "best epoch 49\n",
            "Epoch 049: | Train Loss: 0.68444235 | Val Loss: 0.68291704 | Train Acc: 0.76107791| Val Acc: 0.76308316\n",
            "best epoch 50\n",
            "Epoch 050: | Train Loss: 0.68417269 | Val Loss: 0.68264068 | Train Acc: 0.76114603| Val Acc: 0.76314371\n",
            "best epoch 51\n",
            "Epoch 051: | Train Loss: 0.68390950 | Val Loss: 0.68236970 | Train Acc: 0.76120809| Val Acc: 0.76324664\n",
            "best epoch 52\n",
            "Epoch 052: | Train Loss: 0.68365226 | Val Loss: 0.68210320 | Train Acc: 0.76124896| Val Acc: 0.76324059\n",
            "best epoch 53\n",
            "Epoch 053: | Train Loss: 0.68340054 | Val Loss: 0.68184100 | Train Acc: 0.76130951| Val Acc: 0.76333747\n",
            "best epoch 54\n",
            "Epoch 054: | Train Loss: 0.68315398 | Val Loss: 0.68158249 | Train Acc: 0.76137914| Val Acc: 0.76344040\n",
            "best epoch 55\n",
            "Epoch 055: | Train Loss: 0.68291225 | Val Loss: 0.68132748 | Train Acc: 0.76142758| Val Acc: 0.76347068\n",
            "best epoch 56\n",
            "Epoch 056: | Train Loss: 0.68267503 | Val Loss: 0.68107594 | Train Acc: 0.76150327| Val Acc: 0.76345857\n",
            "best epoch 57\n",
            "Epoch 057: | Train Loss: 0.68244212 | Val Loss: 0.68082759 | Train Acc: 0.76155171| Val Acc: 0.76351912\n",
            "best epoch 58\n",
            "Epoch 058: | Train Loss: 0.68221329 | Val Loss: 0.68058236 | Train Acc: 0.76161832| Val Acc: 0.76357362\n",
            "best epoch 59\n",
            "Epoch 059: | Train Loss: 0.68198829 | Val Loss: 0.68034036 | Train Acc: 0.76165919| Val Acc: 0.76367655\n",
            "best epoch 60\n",
            "Epoch 060: | Train Loss: 0.68176712 | Val Loss: 0.68010170 | Train Acc: 0.76170460| Val Acc: 0.76368261\n",
            "best epoch 61\n",
            "Epoch 061: | Train Loss: 0.68154960 | Val Loss: 0.67986630 | Train Acc: 0.76174699| Val Acc: 0.76373710\n",
            "best epoch 62\n",
            "Epoch 062: | Train Loss: 0.68133561 | Val Loss: 0.67963430 | Train Acc: 0.76181813| Val Acc: 0.76372499\n",
            "best epoch 63\n",
            "Epoch 063: | Train Loss: 0.68112508 | Val Loss: 0.67940572 | Train Acc: 0.76188777| Val Acc: 0.76380371\n",
            "best epoch 64\n",
            "Epoch 064: | Train Loss: 0.68091802 | Val Loss: 0.67918067 | Train Acc: 0.76196194| Val Acc: 0.76384004\n",
            "best epoch 65\n",
            "Epoch 065: | Train Loss: 0.68071432 | Val Loss: 0.67895935 | Train Acc: 0.76203309| Val Acc: 0.76386426\n",
            "best epoch 66\n",
            "Epoch 066: | Train Loss: 0.68051399 | Val Loss: 0.67874179 | Train Acc: 0.76206942| Val Acc: 0.76389453\n",
            "best epoch 67\n",
            "Epoch 067: | Train Loss: 0.68031697 | Val Loss: 0.67852823 | Train Acc: 0.76212694| Val Acc: 0.76390664\n",
            "best epoch 68\n",
            "Epoch 068: | Train Loss: 0.68012329 | Val Loss: 0.67831840 | Train Acc: 0.76216630| Val Acc: 0.76393086\n",
            "best epoch 69\n",
            "Epoch 069: | Train Loss: 0.67993286 | Val Loss: 0.67811260 | Train Acc: 0.76219506| Val Acc: 0.76395508\n",
            "best epoch 70\n",
            "Epoch 070: | Train Loss: 0.67974569 | Val Loss: 0.67791065 | Train Acc: 0.76225258| Val Acc: 0.76393086\n",
            "best epoch 71\n",
            "Epoch 071: | Train Loss: 0.67956172 | Val Loss: 0.67771242 | Train Acc: 0.76226923| Val Acc: 0.76401563\n",
            "best epoch 72\n",
            "Epoch 072: | Train Loss: 0.67938090 | Val Loss: 0.67751767 | Train Acc: 0.76232676| Val Acc: 0.76409435\n",
            "best epoch 73\n",
            "Epoch 073: | Train Loss: 0.67920315 | Val Loss: 0.67732669 | Train Acc: 0.76237520| Val Acc: 0.76414884\n",
            "best epoch 74\n",
            "Epoch 074: | Train Loss: 0.67902839 | Val Loss: 0.67713895 | Train Acc: 0.76242969| Val Acc: 0.76415490\n",
            "best epoch 75\n",
            "Epoch 075: | Train Loss: 0.67885648 | Val Loss: 0.67695441 | Train Acc: 0.76249327| Val Acc: 0.76423361\n",
            "best epoch 76\n",
            "Epoch 076: | Train Loss: 0.67868742 | Val Loss: 0.67677291 | Train Acc: 0.76255987| Val Acc: 0.76425783\n",
            "best epoch 77\n",
            "Epoch 077: | Train Loss: 0.67852105 | Val Loss: 0.67659415 | Train Acc: 0.76258864| Val Acc: 0.76427600\n",
            "best epoch 78\n",
            "Epoch 078: | Train Loss: 0.67835724 | Val Loss: 0.67641795 | Train Acc: 0.76264465| Val Acc: 0.76426389\n",
            "best epoch 79\n",
            "Epoch 079: | Train Loss: 0.67819593 | Val Loss: 0.67624445 | Train Acc: 0.76269006| Val Acc: 0.76430627\n",
            "best epoch 80\n",
            "Epoch 080: | Train Loss: 0.67803706 | Val Loss: 0.67607329 | Train Acc: 0.76271731| Val Acc: 0.76435471\n",
            "best epoch 81\n",
            "Epoch 081: | Train Loss: 0.67788049 | Val Loss: 0.67590447 | Train Acc: 0.76276726| Val Acc: 0.76432444\n",
            "best epoch 82\n",
            "Epoch 082: | Train Loss: 0.67772611 | Val Loss: 0.67573794 | Train Acc: 0.76279753| Val Acc: 0.76431233\n",
            "best epoch 83\n",
            "Epoch 083: | Train Loss: 0.67757388 | Val Loss: 0.67557356 | Train Acc: 0.76284900| Val Acc: 0.76436682\n",
            "best epoch 84\n",
            "Epoch 084: | Train Loss: 0.67742371 | Val Loss: 0.67541117 | Train Acc: 0.76287625| Val Acc: 0.76433655\n",
            "best epoch 85\n",
            "Epoch 085: | Train Loss: 0.67727554 | Val Loss: 0.67525099 | Train Acc: 0.76289896| Val Acc: 0.76437893\n",
            "best epoch 86\n",
            "Epoch 086: | Train Loss: 0.67712928 | Val Loss: 0.67509281 | Train Acc: 0.76288231| Val Acc: 0.76442151\n",
            "best epoch 87\n",
            "Epoch 087: | Train Loss: 0.67698491 | Val Loss: 0.67493659 | Train Acc: 0.76289139| Val Acc: 0.76438518\n",
            "best epoch 88\n",
            "Epoch 088: | Train Loss: 0.67684234 | Val Loss: 0.67478224 | Train Acc: 0.76294740| Val Acc: 0.76440940\n",
            "best epoch 89\n",
            "Epoch 089: | Train Loss: 0.67670150 | Val Loss: 0.67462982 | Train Acc: 0.76297616| Val Acc: 0.76443362\n",
            "best epoch 90\n",
            "Epoch 090: | Train Loss: 0.67656234 | Val Loss: 0.67447920 | Train Acc: 0.76302914| Val Acc: 0.76446995\n",
            "best epoch 91\n",
            "Epoch 091: | Train Loss: 0.67642476 | Val Loss: 0.67433025 | Train Acc: 0.76304730| Val Acc: 0.76448206\n",
            "best epoch 92\n",
            "Epoch 092: | Train Loss: 0.67628877 | Val Loss: 0.67418317 | Train Acc: 0.76304730| Val Acc: 0.76446995\n",
            "best epoch 93\n",
            "Epoch 093: | Train Loss: 0.67615429 | Val Loss: 0.67403775 | Train Acc: 0.76307607| Val Acc: 0.76449417\n",
            "best epoch 94\n",
            "Epoch 094: | Train Loss: 0.67602132 | Val Loss: 0.67389412 | Train Acc: 0.76309574| Val Acc: 0.76455472\n",
            "best epoch 95\n",
            "Epoch 095: | Train Loss: 0.67588980 | Val Loss: 0.67375218 | Train Acc: 0.76312451| Val Acc: 0.76457289\n",
            "best epoch 96\n",
            "Epoch 096: | Train Loss: 0.67575969 | Val Loss: 0.67361167 | Train Acc: 0.76317900| Val Acc: 0.76462133\n",
            "best epoch 97\n",
            "Epoch 097: | Train Loss: 0.67563093 | Val Loss: 0.67347290 | Train Acc: 0.76320322| Val Acc: 0.76461528\n",
            "best epoch 98\n",
            "Epoch 098: | Train Loss: 0.67550353 | Val Loss: 0.67333567 | Train Acc: 0.76323501| Val Acc: 0.76465766\n",
            "best epoch 99\n",
            "Epoch 099: | Train Loss: 0.67537741 | Val Loss: 0.67319982 | Train Acc: 0.76325015| Val Acc: 0.76468188\n",
            "best epoch 100\n",
            "Epoch 100: | Train Loss: 0.67525259 | Val Loss: 0.67306559 | Train Acc: 0.76325318| Val Acc: 0.76473032\n",
            "best epoch 101\n",
            "Epoch 101: | Train Loss: 0.67512898 | Val Loss: 0.67293278 | Train Acc: 0.76325166| Val Acc: 0.76474849\n",
            "best epoch 102\n",
            "Epoch 102: | Train Loss: 0.67500660 | Val Loss: 0.67280156 | Train Acc: 0.76327437| Val Acc: 0.76476060\n",
            "best epoch 103\n",
            "Epoch 103: | Train Loss: 0.67488541 | Val Loss: 0.67267146 | Train Acc: 0.76329556| Val Acc: 0.76479087\n",
            "best epoch 104\n",
            "Epoch 104: | Train Loss: 0.67476536 | Val Loss: 0.67254295 | Train Acc: 0.76331978| Val Acc: 0.76479087\n",
            "best epoch 105\n",
            "Epoch 105: | Train Loss: 0.67464647 | Val Loss: 0.67241570 | Train Acc: 0.76334097| Val Acc: 0.76479087\n",
            "best epoch 106\n",
            "Epoch 106: | Train Loss: 0.67452868 | Val Loss: 0.67228974 | Train Acc: 0.76335611| Val Acc: 0.76481509\n",
            "best epoch 107\n",
            "Epoch 107: | Train Loss: 0.67441197 | Val Loss: 0.67216516 | Train Acc: 0.76337579| Val Acc: 0.76482720\n",
            "best epoch 108\n",
            "Epoch 108: | Train Loss: 0.67429634 | Val Loss: 0.67204182 | Train Acc: 0.76339093| Val Acc: 0.76483326\n",
            "best epoch 109\n",
            "Epoch 109: | Train Loss: 0.67418175 | Val Loss: 0.67191971 | Train Acc: 0.76338941| Val Acc: 0.76480298\n",
            "best epoch 110\n",
            "Epoch 110: | Train Loss: 0.67406818 | Val Loss: 0.67179878 | Train Acc: 0.76340455| Val Acc: 0.76481509\n",
            "best epoch 111\n",
            "Epoch 111: | Train Loss: 0.67395563 | Val Loss: 0.67167904 | Train Acc: 0.76342120| Val Acc: 0.76482115\n",
            "best epoch 112\n",
            "Epoch 112: | Train Loss: 0.67384406 | Val Loss: 0.67156050 | Train Acc: 0.76343180| Val Acc: 0.76484537\n",
            "best epoch 113\n",
            "Epoch 113: | Train Loss: 0.67373345 | Val Loss: 0.67144317 | Train Acc: 0.76345299| Val Acc: 0.76484537\n",
            "best epoch 114\n",
            "Epoch 114: | Train Loss: 0.67362381 | Val Loss: 0.67132682 | Train Acc: 0.76348478| Val Acc: 0.76486353\n",
            "best epoch 115\n",
            "Epoch 115: | Train Loss: 0.67351511 | Val Loss: 0.67121163 | Train Acc: 0.76350295| Val Acc: 0.76492408\n",
            "best epoch 116\n",
            "Epoch 116: | Train Loss: 0.67340734 | Val Loss: 0.67109757 | Train Acc: 0.76350597| Val Acc: 0.76491803\n",
            "best epoch 117\n",
            "Epoch 117: | Train Loss: 0.67330048 | Val Loss: 0.67098450 | Train Acc: 0.76353625| Val Acc: 0.76493014\n",
            "best epoch 118\n",
            "Epoch 118: | Train Loss: 0.67319452 | Val Loss: 0.67087247 | Train Acc: 0.76352717| Val Acc: 0.76494830\n",
            "best epoch 119\n",
            "Epoch 119: | Train Loss: 0.67308942 | Val Loss: 0.67076162 | Train Acc: 0.76358317| Val Acc: 0.76497858\n",
            "best epoch 120\n",
            "Epoch 120: | Train Loss: 0.67298522 | Val Loss: 0.67065169 | Train Acc: 0.76363010| Val Acc: 0.76496647\n",
            "best epoch 121\n",
            "Epoch 121: | Train Loss: 0.67288186 | Val Loss: 0.67054279 | Train Acc: 0.76364221| Val Acc: 0.76499069\n",
            "best epoch 122\n",
            "Epoch 122: | Train Loss: 0.67277937 | Val Loss: 0.67043482 | Train Acc: 0.76366189| Val Acc: 0.76502096\n",
            "best epoch 123\n",
            "Epoch 123: | Train Loss: 0.67267768 | Val Loss: 0.67032784 | Train Acc: 0.76367703| Val Acc: 0.76506940\n",
            "best epoch 124\n",
            "Epoch 124: | Train Loss: 0.67257682 | Val Loss: 0.67022187 | Train Acc: 0.76370428| Val Acc: 0.76510573\n",
            "best epoch 125\n",
            "Epoch 125: | Train Loss: 0.67247679 | Val Loss: 0.67011671 | Train Acc: 0.76373304| Val Acc: 0.76513601\n",
            "best epoch 126\n",
            "Epoch 126: | Train Loss: 0.67237758 | Val Loss: 0.67001263 | Train Acc: 0.76373606| Val Acc: 0.76513601\n",
            "best epoch 127\n",
            "Epoch 127: | Train Loss: 0.67227912 | Val Loss: 0.66990929 | Train Acc: 0.76374212| Val Acc: 0.76512995\n",
            "best epoch 128\n",
            "Epoch 128: | Train Loss: 0.67218146 | Val Loss: 0.66980694 | Train Acc: 0.76373758| Val Acc: 0.76517234\n",
            "best epoch 129\n",
            "Epoch 129: | Train Loss: 0.67208458 | Val Loss: 0.66970543 | Train Acc: 0.76374817| Val Acc: 0.76513601\n",
            "best epoch 130\n",
            "Epoch 130: | Train Loss: 0.67198844 | Val Loss: 0.66960485 | Train Acc: 0.76375574| Val Acc: 0.76512390\n",
            "best epoch 131\n",
            "Epoch 131: | Train Loss: 0.67189305 | Val Loss: 0.66950508 | Train Acc: 0.76378905| Val Acc: 0.76512995\n",
            "best epoch 132\n",
            "Epoch 132: | Train Loss: 0.67179837 | Val Loss: 0.66940615 | Train Acc: 0.76381024| Val Acc: 0.76514206\n",
            "best epoch 133\n",
            "Epoch 133: | Train Loss: 0.67170448 | Val Loss: 0.66930815 | Train Acc: 0.76381629| Val Acc: 0.76517234\n",
            "best epoch 134\n",
            "Epoch 134: | Train Loss: 0.67161131 | Val Loss: 0.66921101 | Train Acc: 0.76381175| Val Acc: 0.76516628\n",
            "best epoch 135\n",
            "Epoch 135: | Train Loss: 0.67151887 | Val Loss: 0.66911455 | Train Acc: 0.76384051| Val Acc: 0.76520261\n",
            "best epoch 136\n",
            "Epoch 136: | Train Loss: 0.67142714 | Val Loss: 0.66901897 | Train Acc: 0.76385262| Val Acc: 0.76522078\n",
            "best epoch 137\n",
            "Epoch 137: | Train Loss: 0.67133612 | Val Loss: 0.66892421 | Train Acc: 0.76384203| Val Acc: 0.76524500\n",
            "best epoch 138\n",
            "Epoch 138: | Train Loss: 0.67124578 | Val Loss: 0.66883022 | Train Acc: 0.76383900| Val Acc: 0.76524500\n",
            "best epoch 139\n",
            "Epoch 139: | Train Loss: 0.67115613 | Val Loss: 0.66873702 | Train Acc: 0.76382689| Val Acc: 0.76529949\n",
            "best epoch 140\n",
            "Epoch 140: | Train Loss: 0.67106715 | Val Loss: 0.66864439 | Train Acc: 0.76382992| Val Acc: 0.76532977\n",
            "best epoch 141\n",
            "Epoch 141: | Train Loss: 0.67097883 | Val Loss: 0.66855271 | Train Acc: 0.76383597| Val Acc: 0.76531766\n",
            "best epoch 142\n",
            "Epoch 142: | Train Loss: 0.67089121 | Val Loss: 0.66846178 | Train Acc: 0.76383294| Val Acc: 0.76534793\n",
            "best epoch 143\n",
            "Epoch 143: | Train Loss: 0.67080419 | Val Loss: 0.66837147 | Train Acc: 0.76387079| Val Acc: 0.76537821\n",
            "best epoch 144\n",
            "Epoch 144: | Train Loss: 0.67071785 | Val Loss: 0.66828193 | Train Acc: 0.76389349| Val Acc: 0.76541454\n",
            "best epoch 145\n",
            "Epoch 145: | Train Loss: 0.67063217 | Val Loss: 0.66819323 | Train Acc: 0.76391620| Val Acc: 0.76547509\n",
            "best epoch 146\n",
            "Epoch 146: | Train Loss: 0.67054714 | Val Loss: 0.66810520 | Train Acc: 0.76393891| Val Acc: 0.76547509\n",
            "best epoch 147\n",
            "Epoch 147: | Train Loss: 0.67046277 | Val Loss: 0.66801792 | Train Acc: 0.76396918| Val Acc: 0.76548114\n",
            "best epoch 148\n",
            "Epoch 148: | Train Loss: 0.67037901 | Val Loss: 0.66793136 | Train Acc: 0.76399492| Val Acc: 0.76548720\n",
            "best epoch 149\n",
            "Epoch 149: | Train Loss: 0.67029590 | Val Loss: 0.66784540 | Train Acc: 0.76403882| Val Acc: 0.76549325\n",
            "best epoch 150\n",
            "Epoch 150: | Train Loss: 0.67021336 | Val Loss: 0.66776016 | Train Acc: 0.76404184| Val Acc: 0.76552353\n",
            "best epoch 151\n",
            "Epoch 151: | Train Loss: 0.67013145 | Val Loss: 0.66767569 | Train Acc: 0.76406152| Val Acc: 0.76551142\n",
            "best epoch 152\n",
            "Epoch 152: | Train Loss: 0.67005017 | Val Loss: 0.66759176 | Train Acc: 0.76407363| Val Acc: 0.76553564\n",
            "best epoch 153\n",
            "Epoch 153: | Train Loss: 0.66996945 | Val Loss: 0.66750856 | Train Acc: 0.76409180| Val Acc: 0.76554775\n",
            "best epoch 154\n",
            "Epoch 154: | Train Loss: 0.66988934 | Val Loss: 0.66742600 | Train Acc: 0.76410693| Val Acc: 0.76553564\n",
            "best epoch 155\n",
            "Epoch 155: | Train Loss: 0.66980982 | Val Loss: 0.66734420 | Train Acc: 0.76412510| Val Acc: 0.76552353\n",
            "best epoch 156\n",
            "Epoch 156: | Train Loss: 0.66973089 | Val Loss: 0.66726299 | Train Acc: 0.76414478| Val Acc: 0.76549325\n",
            "best epoch 157\n",
            "Epoch 157: | Train Loss: 0.66965253 | Val Loss: 0.66718238 | Train Acc: 0.76415992| Val Acc: 0.76550536\n",
            "best epoch 158\n",
            "Epoch 158: | Train Loss: 0.66957478 | Val Loss: 0.66710246 | Train Acc: 0.76417051| Val Acc: 0.76551747\n",
            "best epoch 159\n",
            "Epoch 159: | Train Loss: 0.66949758 | Val Loss: 0.66702320 | Train Acc: 0.76419170| Val Acc: 0.76555380\n",
            "best epoch 160\n",
            "Epoch 160: | Train Loss: 0.66942097 | Val Loss: 0.66694450 | Train Acc: 0.76423409| Val Acc: 0.76557197\n",
            "best epoch 161\n",
            "Epoch 161: | Train Loss: 0.66934490 | Val Loss: 0.66686640 | Train Acc: 0.76424771| Val Acc: 0.76559619\n",
            "best epoch 162\n",
            "Epoch 162: | Train Loss: 0.66926938 | Val Loss: 0.66678898 | Train Acc: 0.76428253| Val Acc: 0.76557802\n",
            "best epoch 163\n",
            "Epoch 163: | Train Loss: 0.66919444 | Val Loss: 0.66671223 | Train Acc: 0.76429767| Val Acc: 0.76560224\n",
            "best epoch 164\n",
            "Epoch 164: | Train Loss: 0.66912004 | Val Loss: 0.66663602 | Train Acc: 0.76429464| Val Acc: 0.76560830\n",
            "best epoch 165\n",
            "Epoch 165: | Train Loss: 0.66904618 | Val Loss: 0.66656040 | Train Acc: 0.76431735| Val Acc: 0.76562041\n",
            "best epoch 166\n",
            "Epoch 166: | Train Loss: 0.66897289 | Val Loss: 0.66648544 | Train Acc: 0.76434762| Val Acc: 0.76563252\n",
            "best epoch 167\n",
            "Epoch 167: | Train Loss: 0.66890013 | Val Loss: 0.66641104 | Train Acc: 0.76438849| Val Acc: 0.76564463\n",
            "best epoch 168\n",
            "Epoch 168: | Train Loss: 0.66882789 | Val Loss: 0.66633726 | Train Acc: 0.76440363| Val Acc: 0.76565674\n",
            "best epoch 169\n",
            "Epoch 169: | Train Loss: 0.66875624 | Val Loss: 0.66626420 | Train Acc: 0.76441423| Val Acc: 0.76567491\n",
            "best epoch 170\n",
            "Epoch 170: | Train Loss: 0.66868509 | Val Loss: 0.66619147 | Train Acc: 0.76444602| Val Acc: 0.76567491\n",
            "best epoch 171\n",
            "Epoch 171: | Train Loss: 0.66861450 | Val Loss: 0.66611962 | Train Acc: 0.76447781| Val Acc: 0.76563252\n",
            "best epoch 172\n",
            "Epoch 172: | Train Loss: 0.66854446 | Val Loss: 0.66604818 | Train Acc: 0.76451262| Val Acc: 0.76562041\n",
            "best epoch 173\n",
            "Epoch 173: | Train Loss: 0.66847498 | Val Loss: 0.66597751 | Train Acc: 0.76454592| Val Acc: 0.76563252\n",
            "best epoch 174\n",
            "Epoch 174: | Train Loss: 0.66840601 | Val Loss: 0.66590723 | Train Acc: 0.76456409| Val Acc: 0.76562041\n",
            "best epoch 175\n",
            "Epoch 175: | Train Loss: 0.66833757 | Val Loss: 0.66583760 | Train Acc: 0.76459134| Val Acc: 0.76561435\n",
            "best epoch 176\n",
            "Epoch 176: | Train Loss: 0.66826960 | Val Loss: 0.66576848 | Train Acc: 0.76461707| Val Acc: 0.76562646\n",
            "best epoch 177\n",
            "Epoch 177: | Train Loss: 0.66820213 | Val Loss: 0.66569989 | Train Acc: 0.76463524| Val Acc: 0.76564463\n",
            "best epoch 178\n",
            "Epoch 178: | Train Loss: 0.66813519 | Val Loss: 0.66563197 | Train Acc: 0.76464129| Val Acc: 0.76565069\n",
            "best epoch 179\n",
            "Epoch 179: | Train Loss: 0.66806874 | Val Loss: 0.66556448 | Train Acc: 0.76465037| Val Acc: 0.76566280\n",
            "best epoch 180\n",
            "Epoch 180: | Train Loss: 0.66800276 | Val Loss: 0.66549750 | Train Acc: 0.76464129| Val Acc: 0.76566280\n",
            "best epoch 181\n",
            "Epoch 181: | Train Loss: 0.66793724 | Val Loss: 0.66543105 | Train Acc: 0.76466702| Val Acc: 0.76566280\n",
            "best epoch 182\n",
            "Epoch 182: | Train Loss: 0.66787223 | Val Loss: 0.66536516 | Train Acc: 0.76468368| Val Acc: 0.76569913\n",
            "best epoch 183\n",
            "Epoch 183: | Train Loss: 0.66780766 | Val Loss: 0.66529965 | Train Acc: 0.76470790| Val Acc: 0.76576573\n",
            "best epoch 184\n",
            "Epoch 184: | Train Loss: 0.66774355 | Val Loss: 0.66523468 | Train Acc: 0.76471395| Val Acc: 0.76576573\n",
            "best epoch 185\n",
            "Epoch 185: | Train Loss: 0.66767991 | Val Loss: 0.66517038 | Train Acc: 0.76475634| Val Acc: 0.76578995\n",
            "best epoch 186\n",
            "Epoch 186: | Train Loss: 0.66761676 | Val Loss: 0.66510645 | Train Acc: 0.76477147| Val Acc: 0.76580812\n",
            "best epoch 187\n",
            "Epoch 187: | Train Loss: 0.66755405 | Val Loss: 0.66504302 | Train Acc: 0.76479418| Val Acc: 0.76580206\n",
            "best epoch 188\n",
            "Epoch 188: | Train Loss: 0.66749175 | Val Loss: 0.66497999 | Train Acc: 0.76481235| Val Acc: 0.76582023\n",
            "best epoch 189\n",
            "Epoch 189: | Train Loss: 0.66742987 | Val Loss: 0.66491748 | Train Acc: 0.76483354| Val Acc: 0.76583839\n",
            "best epoch 190\n",
            "Epoch 190: | Train Loss: 0.66736847 | Val Loss: 0.66485548 | Train Acc: 0.76484716| Val Acc: 0.76588683\n",
            "best epoch 191\n",
            "Epoch 191: | Train Loss: 0.66730752 | Val Loss: 0.66479393 | Train Acc: 0.76486079| Val Acc: 0.76591105\n",
            "best epoch 192\n",
            "Epoch 192: | Train Loss: 0.66724700 | Val Loss: 0.66473288 | Train Acc: 0.76488955| Val Acc: 0.76592922\n",
            "best epoch 193\n",
            "Epoch 193: | Train Loss: 0.66718692 | Val Loss: 0.66467217 | Train Acc: 0.76491074| Val Acc: 0.76592922\n",
            "best epoch 194\n",
            "Epoch 194: | Train Loss: 0.66712725 | Val Loss: 0.66461212 | Train Acc: 0.76491982| Val Acc: 0.76597160\n",
            "best epoch 195\n",
            "Epoch 195: | Train Loss: 0.66706800 | Val Loss: 0.66455226 | Train Acc: 0.76492436| Val Acc: 0.76593527\n",
            "best epoch 196\n",
            "Epoch 196: | Train Loss: 0.66700913 | Val Loss: 0.66449296 | Train Acc: 0.76495615| Val Acc: 0.76595949\n",
            "best epoch 197\n",
            "Epoch 197: | Train Loss: 0.66695069 | Val Loss: 0.66443413 | Train Acc: 0.76498643| Val Acc: 0.76600188\n",
            "best epoch 198\n",
            "Epoch 198: | Train Loss: 0.66689267 | Val Loss: 0.66437564 | Train Acc: 0.76501368| Val Acc: 0.76605637\n",
            "best epoch 199\n",
            "Epoch 199: | Train Loss: 0.66683501 | Val Loss: 0.66431749 | Train Acc: 0.76502730| Val Acc: 0.76605032\n",
            "best epoch 200\n",
            "Epoch 200: | Train Loss: 0.66677775 | Val Loss: 0.66425986 | Train Acc: 0.76503638| Val Acc: 0.76606848\n",
            "\n",
            "Model - Post-training AnfisNet(\n",
            "  Rule  0: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.4421635568141937], [1.0], [0.06646770238876343], [0.3641345798969269], [0.7596837878227234], [0.0]]\n",
            "  Rule  1: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.6414741277694702], [0.1184004545211792], [0.9999999403953552], [0.5047373175621033], [0.0], [0.6469008922576904]]\n",
            "  Rule  2: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.9374051094055176], [0.0], [0.9999998807907104], [0.9431195259094238], [0.2577781677246094], [0.7272371053695679]]\n",
            "  Rule  3: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.5610756278038025], [0.49613088369369507], [0.39878928661346436], [0.4204648733139038], [0.0], [1.0]]\n",
            "  Rule  4: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.5016751289367676], [0.8337357044219971], [0.0], [0.003282785415649414], [0.599418044090271], [1.0]]\n",
            "  Rule  5: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.6217464208602905], [1.0], [0.698433518409729], [0.0], [0.2598578929901123], [0.33401286602020264]]\n",
            "  Rule  6: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.7354511022567749], [0.0], [0.9231282472610474], [0.9535263776779175], [0.8592745065689087], [1.0]]\n",
            "  Rule  7: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.3079681694507599], [1.0], [0.24527928233146667], [0.33585014939308167], [0.6395497918128967]]\n",
            "  Rule  8: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.5094162225723267], [0.0], [0.560556173324585], [0.6948983073234558], [1.0], [0.5837289690971375]]\n",
            "  Rule  9: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.26296064257621765], [0.7006679177284241], [0.7463316917419434], [0.8148239254951477], [1.0]]\n",
            "  Rule 10: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.5790101289749146], [1.0], [0.5834478735923767], [0.6930020451545715], [0.9295914173126221]]\n",
            "  Rule 11: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.8359476327896118], [0.09335261583328247], [1.0], [0.7829087376594543], [0.3992401957511902]]\n",
            "  Rule 12: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[1.0], [0.8998745083808899], [0.18419700860977173], [0.9914893507957458], [0.0], [0.9015321135520935]]\n",
            "  Rule 13: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.2808833122253418], [0.21203598380088806], [0.7316096425056458], [0.021414905786514282], [0.0]]\n",
            "  Rule 14: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.931655764579773], [0.9117158055305481], [0.05601310729980469], [0.8982051610946655], [1.0]]\n",
            "  Rule 15: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[1.0], [0.8453514575958252], [0.9886927604675293], [0.3982735574245453], [0.0], [0.7267948389053345]]\n",
            "  Rule 16: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.9713845252990723], [0.9999999403953552], [0.958280086517334], [0.8376466631889343], [0.0], [0.10837686061859131]]\n",
            "  Rule 17: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.6604379415512085], [0.5630114078521729], [1.0], [0.0], [0.26453444361686707], [0.6744831204414368]]\n",
            "  Rule 18: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.31762897968292236], [0.3007049262523651], [0.784568190574646], [0.9999998807907104], [0.7319031953811646], [0.0]]\n",
            "  Rule 19: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.2866075336933136], [0.9999999403953552], [0.8733861446380615], [0.5141475796699524], [0.09935951232910156]]\n",
            "  Rule 20: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.743229866027832], [0.59024578332901], [0.7244583964347839], [1.0], [0.7873830199241638], [0.0]]\n",
            "  Rule 21: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.8436715602874756], [1.0], [0.3881973326206207], [0.8351085186004639], [0.11495798826217651], [0.0]]\n",
            "  Rule 22: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.6196828484535217], [0.5575394630432129], [0.9767630100250244], [0.3369317650794983], [0.0]]\n",
            "  Rule 23: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.7124403119087219], [0.6369979381561279], [0.3083641231060028], [1.0], [0.11508184671401978], [0.0]]\n",
            "  Rule 24: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[1.0], [0.9124021530151367], [0.4704400300979614], [0.8567302823066711], [0.0], [0.32124465703964233]]\n",
            "  Rule 25: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[1.0], [0.9592042565345764], [0.8609305024147034], [0.7769233584403992], [0.08381050825119019], [0.0]]\n",
            "  Rule 26: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.9931921362876892], [1.0], [0.002986431121826172], [0.9695556163787842], [0.0], [0.25778210163116455]]\n",
            "  Rule 27: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[1.0], [0.27206137776374817], [0.4538794755935669], [0.6373423933982849], [0.6273412704467773], [0.0]]\n",
            "  Rule 28: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.9552959203720093], [0.6405700445175171], [0.27401041984558105], [0.9999999403953552], [0.8311275243759155], [0.0]]\n",
            "  Rule 29: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.39795923233032227], [0.6401022672653198], [0.20380324125289917], [0.0], [0.34848570823669434], [1.0]]\n",
            "  Rule 30: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.9670805931091309], [1.0], [0.5493338704109192], [0.3615724444389343], [0.6223026514053345], [0.0]]\n",
            "  Rule 31: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.8262354731559753], [0.7919051051139832], [1.0], [0.0], [0.8956411480903625], [0.1708235740661621]]\n",
            "  Rule 32: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[1.0], [0.6080503463745117], [0.6671013832092285], [0.8813091516494751], [0.6151190400123596], [0.0]]\n",
            "  Rule 33: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.6217466592788696], [0.42264798283576965], [0.7307524681091309], [1.0], [0.15280956029891968]]\n",
            "  Rule 34: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.2631582021713257], [1.0], [0.5242767333984375], [0.0], [0.6443790197372437], [0.1852448284626007]]\n",
            "  Rule 35: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.235487163066864], [0.661891758441925], [0.9642015695571899], [1.0], [0.3915024995803833]]\n",
            "  Rule 36: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.7545581459999084], [0.7399076223373413], [0.9293143153190613], [0.7583417892456055], [1.0]]\n",
            "  Rule 37: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.5434156060218811], [0.617709219455719], [0.9137859344482422], [0.6120124459266663], [1.0]]\n",
            "  Rule 38: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.5622572302818298], [0.43546268343925476], [0.5806297063827515], [0.0], [0.4127965569496155], [1.0000001192092896]]\n",
            "  Rule 39: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.31296345591545105], [0.2321295440196991], [0.16365523636341095], [0.0], [0.43036943674087524], [1.0]]\n",
            "  Rule 40: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.30793464183807373], [0.26781558990478516], [0.09973818063735962], [0.0], [0.2731916904449463], [1.0]]\n",
            "  Rule 41: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.3334817886352539], [0.26072025299072266], [0.0], [0.08773235976696014], [0.44629132747650146], [1.0]]\n",
            "  Rule 42: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.5920968055725098], [0.46833404898643494], [0.25421786308288574], [0.9999998807907104], [0.0], [0.642756998538971]]\n",
            "  Rule 43: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[1.0], [0.7926571369171143], [0.6194202899932861], [0.0], [0.381609708070755], [0.6166220307350159]]\n",
            "  Rule 44: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[1.0], [0.5423462390899658], [0.0], [0.14847546815872192], [0.31441736221313477], [0.7330249547958374]]\n",
            "  Rule 45: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.006382852792739868], [0.14843760430812836], [0.46429404616355896], [0.9999999403953552], [0.19646261632442474], [0.0]]\n",
            "  Rule 46: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.14190194010734558], [0.5817446708679199], [1.0], [0.3231154680252075], [0.4643709361553192]]\n",
            "  Rule 47: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.50875324010849], [0.2832093834877014], [0.6271198987960815], [1.0], [0.32680100202560425], [0.0]]\n",
            "  Rule 48: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.4182044565677643], [1.0], [0.6086534857749939], [0.6017875075340271], [0.19573712348937988]]\n",
            "  Rule 49: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.07382318377494812], [0.0], [0.9999999403953552], [0.6739780306816101], [0.4212076961994171], [0.6165536642074585]]\n",
            "  Rule 50: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.39819854497909546], [0.5936334133148193], [1.0], [0.6441265940666199], [0.712138295173645], [0.0]]\n",
            "  Rule 51: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.8932509422302246], [0.9138926863670349], [0.0], [1.0], [0.283860445022583], [0.30794480443000793]]\n",
            "  Rule 52: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.7469459772109985], [1.0], [0.0], [0.9024017453193665], [0.32861465215682983], [0.30014100670814514]]\n",
            "  Rule 53: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.6176804304122925], [0.7641124725341797], [1.0], [0.6594059467315674], [0.5894871950149536], [0.0]]\n",
            "  Rule 54: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.43598878383636475], [0.0], [0.6253843903541565], [0.24637264013290405], [0.3655782639980316], [1.0]]\n",
            "  Rule 55: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.6617751121520996], [0.04587578773498535], [0.9999998807907104], [0.0], [0.35218796133995056], [0.3660051226615906]]\n",
            "  Rule 56: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.32681041955947876], [0.8737776279449463], [0.0], [0.9999998807907104], [0.9350204467773438], [0.7881327867507935]]\n",
            "  Rule 57: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.7428354024887085], [0.5579900145530701], [1.0], [0.0], [0.14355573058128357], [0.40919336676597595]]\n",
            "  Rule 58: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.5185501575469971], [0.5228857398033142], [0.9999998807907104], [0.170414537191391], [0.2747885584831238], [0.0]]\n",
            "  Rule 59: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.9894294738769531], [0.3764708936214447], [0.9561282992362976], [0.44944220781326294], [0.0], [1.0]]\n",
            "  Rule 60: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[1.0], [0.767466127872467], [0.507394552230835], [0.37675797939300537], [0.0], [0.14324110746383667]]\n",
            "  Rule 61: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.9162719249725342], [1.0], [0.759013295173645], [0.330635130405426], [0.48849764466285706], [0.0]]\n",
            "  Rule 62: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.5557926297187805], [0.554680585861206], [0.007876366376876831], [1.0], [0.0], [0.5637714862823486]]\n",
            "  Rule 63: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.5272647142410278], [0.8108768463134766], [0.0], [1.0], [0.8868995308876038], [0.562877357006073]]\n",
            "  Rule 64: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.8535788655281067], [0.9375183582305908], [0.0], [0.8426465392112732], [1.0], [0.6325491666793823]]\n",
            "  Rule 65: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.4500177502632141], [0.6581730842590332], [0.5514031648635864], [0.7208136320114136], [0.9999998807907104], [0.0]]\n",
            "  Rule 66: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.9861370325088501], [0.5564209222793579], [0.9999999403953552], [0.6134580373764038], [0.8940140008926392], [0.0]]\n",
            "  Rule 67: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.9999999403953552], [0.890068531036377], [0.7889307141304016], [0.9964689612388611], [0.8174852728843689], [0.0]]\n",
            "  Rule 68: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.7763223052024841], [0.8386307954788208], [0.0], [0.5360056161880493], [0.0969921350479126], [1.0]]\n",
            "  Rule 69: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.5075786709785461], [0.8828963041305542], [0.9999999403953552], [0.46481576561927795], [0.88480544090271], [0.0]]\n",
            "  Rule 70: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.8222669363021851], [0.7949193716049194], [0.9999999403953552], [0.8725959658622742], [0.9757041335105896], [0.0]]\n",
            "  Rule 71: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.27997657656669617], [0.06380055844783783], [0.21463413536548615], [0.0], [0.22104278206825256], [1.0]]\n",
            "  Rule 72: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.4887700080871582], [0.9999999403953552], [0.13293194770812988], [0.813704252243042], [0.32890671491622925], [0.0]]\n",
            "  Rule 73: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.48907315731048584], [1.0], [0.0], [0.5402703285217285], [0.7825232148170471], [0.3750419616699219]]\n",
            "  Rule 74: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.8788989782333374], [1.0], [0.9000673294067383], [0.7703356742858887], [0.409786194562912], [0.0]]\n",
            "  Rule 75: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.4540366232395172], [0.739380955696106], [0.7279301285743713], [0.539237380027771], [0.9999999403953552], [0.0]]\n",
            "  Rule 76: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.852015495300293], [0.8487172722816467], [0.8959819078445435], [0.7763383388519287], [1.0], [0.0]]\n",
            "  Rule 77: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.7448332905769348], [0.0], [0.35590484738349915], [0.9999999403953552], [0.5192535519599915], [0.6752910614013672]]\n",
            "  Rule 78: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.8993538618087769], [0.740215539932251], [1.0], [0.6590652465820312], [0.4718036651611328], [0.0]]\n",
            "  Rule 79: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.9587852358818054], [0.940863311290741], [1.0], [0.7469560503959656], [0.8073263168334961], [0.0]]\n",
            "  Rule 80: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.12407612800598145], [0.09580826759338379], [0.0], [0.3824993968009949], [0.5178532600402832], [1.0]]\n",
            "  (layer): ModuleDict(\n",
            "    (fuzzify): Input variables\n",
            "    Variable x0\n",
            "    - mf0: GaussMembFunc(mu=5.100895404815674, sigma=40.79579544067383)\n",
            "    - mf1: GaussMembFunc(mu=94.02462768554688, sigma=41.86771774291992)\n",
            "    - mf2: GaussMembFunc(mu=144.00006103515625, sigma=35.7569694519043)\n",
            "    Variable x1\n",
            "    - mf0: GaussMembFunc(mu=-0.3519868552684784, sigma=42.18938064575195)\n",
            "    - mf1: GaussMembFunc(mu=117.4415054321289, sigma=42.91695785522461)\n",
            "    - mf2: GaussMembFunc(mu=171.13465881347656, sigma=42.58596420288086)\n",
            "    Variable x2\n",
            "    - mf0: GaussMembFunc(mu=-1.5688655376434326, sigma=49.44496154785156)\n",
            "    - mf1: GaussMembFunc(mu=98.28691864013672, sigma=39.99428176879883)\n",
            "    - mf2: GaussMembFunc(mu=182.96466064453125, sigma=50.80499267578125)\n",
            "    Variable x3\n",
            "    - mf0: GaussMembFunc(mu=0.14224199950695038, sigma=2.708850622177124)\n",
            "    - mf1: GaussMembFunc(mu=2.1734097003936768, sigma=-0.6657853126525879)\n",
            "    - mf2: GaussMembFunc(mu=5.867845058441162, sigma=2.1888036727905273)\n",
            "    (rules): AntecedentLayer()\n",
            "    (consequent): PlainConsequentLayer()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RISULTATI TEST\n",
            "270742 of 353895 correct (accuracy=76.50%)\n",
            "tensor([5, 3, 1,  ..., 1, 3, 2])\n",
            "[[57255  2960  4354  3274   375    38]\n",
            " [ 5798 20077  4711  7794  2363   893]\n",
            " [ 5449  4879 48615  5011  1324   408]\n",
            " [ 6252  4860  2386 72245  4337   899]\n",
            " [  816   437  5232  2983 29094    91]\n",
            " [   88   595    57  4388   101 43456]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.84      0.80     68256\n",
            "         1.0       0.59      0.48      0.53     41636\n",
            "         2.0       0.74      0.74      0.74     65686\n",
            "         3.0       0.75      0.79      0.77     90979\n",
            "         4.0       0.77      0.75      0.76     38653\n",
            "         5.0       0.95      0.89      0.92     48685\n",
            "\n",
            "    accuracy                           0.77    353895\n",
            "   macro avg       0.76      0.75      0.75    353895\n",
            "weighted avg       0.76      0.77      0.76    353895\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY0ld16Kvg4K"
      },
      "source": [
        "# Test 3\n",
        "\n",
        "In the following test I choose to configure the ANFIS training with:\n",
        "\n",
        "\n",
        "*   Nr. 4 Fuzzy Sets\n",
        "*   32 of Batch size\n",
        "*   Nr. 100 of epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e1d40b72ec90411ca7c8e83393e3cbd7",
            "f9af9208ae8a4aa1943ea858b9f10518",
            "b9ee658c147446ed9dbdfa1b5dd2e1ad",
            "71e7eb62bcf4428ab984e1262912c66f",
            "e651602a51394ed09ea47aaa87be1493",
            "b412dc9d20304ccf84fac639e12487fa",
            "a9eb2b5815424654b6e861ea9936d562",
            "d7561bc2dbbd40159e1160a9db4d1fea"
          ]
        },
        "id": "U6kSVWCGwXKD",
        "outputId": "46edc5dd-5938-4e99-b39f-65dcafdd8834"
      },
      "source": [
        "dataset = 'datasets/reducedTopClass/reducedTC.csv'\n",
        "model = None\n",
        "n_terms = 4 #IMPOSTA NUMERO DI FUZZY SET\n",
        "batch_size = 32\n",
        "num_categories = 6 #IMPOSTA NUMERO DI CLASSI\n",
        "epoch = 200\n",
        "model_l = False #SEMPRE A FALSE\n",
        "hybrid = False #SEMPRE A FALSE\n",
        "i = 0\n",
        "lista_acc = []\n",
        "k_fold = False\n",
        "\n",
        "# Make the classes available via (controlled) reflection:\n",
        "get_class_for = {n: globals()[n]\n",
        "                 for n in ['BellMembFunc',\n",
        "                           'GaussMembFunc',\n",
        "                           'TriangularMembFunc',\n",
        "                           'TrapezoidalMembFunc',\n",
        "                           ]}\n",
        "\n",
        "# DEFINIRE LA MEMBERSHIP FUNCTION ATTUALMENTE E' ABILITATA SOLO GAUSSIANA E TRIANGOLARE\n",
        "membership_function = get_class_for['GaussMembFunc']\n",
        "\n",
        "d_data, d_target = split_dataset(dataset)\n",
        "\n",
        "\n",
        "# Split train into trainval-test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(d_data, d_target, test_size=0.3, shuffle=True,\n",
        "                                                          stratify=d_target, random_state=42)\n",
        "\n",
        "# Split train into train-val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, shuffle=True,\n",
        "                                               stratify=y_trainval, random_state=42)\n",
        "\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val, n_terms, num_categories,\n",
        "                                   batch_size, epoch, model_l, hybrid, membership_function, i)\n",
        "\n",
        "torch.save(model, 'models/G_model_geo_' + str(4) + 'topClass' '.h5')\n",
        "\n",
        "model = torch.load('models/G_model_geo_4topClass.h5')\n",
        "\n",
        "test_model(model, X_test, y_test, num_categories, k_fold, i, lista_acc)\n",
        "\n",
        "model = torch.load('models/G_model_geo_4topClass.h5')\n",
        "\n",
        "X_test = torch.Tensor(X_test)\n",
        "\n",
        "y_pred = model(X_test)\n",
        "\n",
        "cat_act = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "#PREDIZIONE SUI DATI DI TEST\n",
        "print(cat_act)\n",
        "\n",
        "cm = confusion_matrix(y_test, cat_act)\n",
        "print(cm)\n",
        "\n",
        "cl = classification_report(y_test, cat_act)\n",
        "print(cl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Model - Pre-training\n",
            "AnfisNet(\n",
            "  Rule  0: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  1: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  2: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  3: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  4: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  5: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  6: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  7: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  8: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule  9: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 10: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 11: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 12: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 13: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 14: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 15: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 16: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 17: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 18: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 19: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 20: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 21: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 22: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 23: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 24: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 25: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 26: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 27: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 28: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 29: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 30: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 31: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 32: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 33: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 34: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 35: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 36: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 37: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 38: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 39: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 40: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 41: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 42: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 43: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 44: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 45: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 46: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 47: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 48: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 49: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 50: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 51: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 52: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 53: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 54: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 55: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 56: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 57: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 58: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 59: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 60: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 61: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 62: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 63: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 64: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 65: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 66: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 67: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 68: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 69: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 70: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 71: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 72: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 73: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 74: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 75: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 76: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 77: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 78: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 79: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 80: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 81: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 82: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 83: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 84: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 85: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 86: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 87: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 88: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 89: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 90: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 91: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 92: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 93: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 94: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 95: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 96: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 97: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 98: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 99: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 100: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 101: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 102: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 103: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 104: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 105: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 106: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 107: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 108: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 109: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 110: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 111: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 112: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 113: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 114: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 115: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 116: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 117: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 118: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 119: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 120: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 121: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 122: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 123: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 124: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 125: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 126: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 127: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 128: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 129: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 130: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 131: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 132: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 133: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 134: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 135: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 136: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 137: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 138: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 139: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 140: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 141: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 142: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 143: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 144: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 145: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 146: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 147: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 148: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 149: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 150: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 151: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 152: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 153: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 154: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 155: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 156: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 157: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 158: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 159: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 160: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 161: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 162: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 163: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 164: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 165: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 166: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 167: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 168: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 169: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 170: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 171: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 172: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 173: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 174: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 175: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 176: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 177: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 178: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 179: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 180: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 181: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 182: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 183: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 184: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 185: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 186: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 187: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 188: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 189: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 190: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 191: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 192: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 193: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 194: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 195: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 196: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 197: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 198: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 199: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 200: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 201: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 202: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 203: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 204: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 205: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 206: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 207: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 208: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 209: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 210: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 211: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 212: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 213: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 214: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 215: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 216: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 217: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 218: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 219: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 220: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 221: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 222: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 223: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 224: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 225: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 226: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 227: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 228: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 229: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 230: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 231: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 232: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 233: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 234: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 235: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 236: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 237: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 238: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 239: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 240: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 241: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 242: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 243: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 244: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 245: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 246: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 247: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 248: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 249: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 250: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 251: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 252: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 253: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 254: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  Rule 255: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
            "  (layer): ModuleDict(\n",
            "    (fuzzify): Input variables\n",
            "    Variable x0\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=62.5)\n",
            "    - mf1: GaussMembFunc(mu=83.33333587646484, sigma=62.5)\n",
            "    - mf2: GaussMembFunc(mu=166.66665649414062, sigma=62.5)\n",
            "    - mf3: GaussMembFunc(mu=250.0, sigma=62.5)\n",
            "    Variable x1\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=63.75)\n",
            "    - mf1: GaussMembFunc(mu=85.0, sigma=63.75)\n",
            "    - mf2: GaussMembFunc(mu=170.0, sigma=63.75)\n",
            "    - mf3: GaussMembFunc(mu=255.0, sigma=63.75)\n",
            "    Variable x2\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=63.75)\n",
            "    - mf1: GaussMembFunc(mu=85.0, sigma=63.75)\n",
            "    - mf2: GaussMembFunc(mu=170.0, sigma=63.75)\n",
            "    - mf3: GaussMembFunc(mu=255.0, sigma=63.75)\n",
            "    Variable x3\n",
            "    - mf0: GaussMembFunc(mu=0.0, sigma=1.214495301246643)\n",
            "    - mf1: GaussMembFunc(mu=1.6193270683288574, sigma=1.214495301246643)\n",
            "    - mf2: GaussMembFunc(mu=3.238654136657715, sigma=1.214495301246643)\n",
            "    - mf3: GaussMembFunc(mu=4.857981204986572, sigma=1.214495301246643)\n",
            "    (rules): AntecedentLayer()\n",
            "    (consequent): PlainConsequentLayer()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1d40b72ec90411ca7c8e83393e3cbd7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best epoch 1\n",
            "Epoch 001: | Train Loss: 0.80815056 | Val Loss: 0.72648585 | Train Acc: 0.71665100| Val Acc: 0.74561440\n",
            "best epoch 2\n",
            "Epoch 002: | Train Loss: 0.71539607 | Val Loss: 0.70640592 | Train Acc: 0.74762212| Val Acc: 0.75209934\n",
            "best epoch 3\n",
            "Epoch 003: | Train Loss: 0.70217955 | Val Loss: 0.69788225 | Train Acc: 0.75221637| Val Acc: 0.75524190\n",
            "best epoch 4\n",
            "Epoch 004: | Train Loss: 0.69545692 | Val Loss: 0.69264597 | Train Acc: 0.75495476| Val Acc: 0.75780317\n",
            "best epoch 5\n",
            "Epoch 005: | Train Loss: 0.69096955 | Val Loss: 0.68882733 | Train Acc: 0.75659870| Val Acc: 0.75898996\n",
            "best epoch 6\n",
            "Epoch 006: | Train Loss: 0.68753287 | Val Loss: 0.68576215 | Train Acc: 0.75780365| Val Acc: 0.75989821\n",
            "best epoch 7\n",
            "Epoch 007: | Train Loss: 0.68468711 | Val Loss: 0.68315172 | Train Acc: 0.75865892| Val Acc: 0.76055821\n",
            "best epoch 8\n",
            "Epoch 008: | Train Loss: 0.68222108 | Val Loss: 0.68084780 | Train Acc: 0.75933254| Val Acc: 0.76129087\n",
            "best epoch 9\n",
            "Epoch 009: | Train Loss: 0.68003797 | Val Loss: 0.67878612 | Train Acc: 0.75988052| Val Acc: 0.76187235\n",
            "best epoch 10\n",
            "Epoch 010: | Train Loss: 0.67810753 | Val Loss: 0.67694418 | Train Acc: 0.76041791| Val Acc: 0.76242336\n",
            "best epoch 11\n",
            "Epoch 011: | Train Loss: 0.67640646 | Val Loss: 0.67527849 | Train Acc: 0.76089474| Val Acc: 0.76293803\n",
            "best epoch 12\n",
            "Epoch 012: | Train Loss: 0.67488147 | Val Loss: 0.67374647 | Train Acc: 0.76131708| Val Acc: 0.76343454\n",
            "best epoch 13\n",
            "Epoch 013: | Train Loss: 0.67348748 | Val Loss: 0.67232358 | Train Acc: 0.76169703| Val Acc: 0.76371308\n",
            "best epoch 14\n",
            "Epoch 014: | Train Loss: 0.67219555 | Val Loss: 0.67099265 | Train Acc: 0.76204974| Val Acc: 0.76418537\n",
            "best epoch 15\n",
            "Epoch 015: | Train Loss: 0.67098657 | Val Loss: 0.66974098 | Train Acc: 0.76236309| Val Acc: 0.76451234\n",
            "best epoch 16\n",
            "Epoch 016: | Train Loss: 0.66984773 | Val Loss: 0.66855904 | Train Acc: 0.76263405| Val Acc: 0.76482115\n",
            "best epoch 17\n",
            "Epoch 017: | Train Loss: 0.66877036 | Val Loss: 0.66744055 | Train Acc: 0.76306850| Val Acc: 0.76505124\n",
            "best epoch 18\n",
            "Epoch 018: | Train Loss: 0.66774895 | Val Loss: 0.66638154 | Train Acc: 0.76336671| Val Acc: 0.76536004\n",
            "best epoch 19\n",
            "Epoch 019: | Train Loss: 0.66677986 | Val Loss: 0.66537806 | Train Acc: 0.76368914| Val Acc: 0.76570518\n",
            "best epoch 20\n",
            "Epoch 020: | Train Loss: 0.66585930 | Val Loss: 0.66442436 | Train Acc: 0.76394648| Val Acc: 0.76589894\n",
            "best epoch 21\n",
            "Epoch 021: | Train Loss: 0.66498197 | Val Loss: 0.66351362 | Train Acc: 0.76423258| Val Acc: 0.76603821\n",
            "best epoch 22\n",
            "Epoch 022: | Train Loss: 0.66414198 | Val Loss: 0.66263912 | Train Acc: 0.76446115| Val Acc: 0.76634701\n",
            "best epoch 23\n",
            "Epoch 023: | Train Loss: 0.66333421 | Val Loss: 0.66179650 | Train Acc: 0.76466551| Val Acc: 0.76670426\n",
            "best epoch 24\n",
            "Epoch 024: | Train Loss: 0.66255475 | Val Loss: 0.66098246 | Train Acc: 0.76488349| Val Acc: 0.76701307\n",
            "best epoch 25\n",
            "Epoch 025: | Train Loss: 0.66180106 | Val Loss: 0.66019534 | Train Acc: 0.76510904| Val Acc: 0.76726132\n",
            "best epoch 26\n",
            "Epoch 026: | Train Loss: 0.66107168 | Val Loss: 0.65943401 | Train Acc: 0.76533308| Val Acc: 0.76742481\n",
            "best epoch 27\n",
            "Epoch 027: | Train Loss: 0.66036579 | Val Loss: 0.65869808 | Train Acc: 0.76556468| Val Acc: 0.76770939\n",
            "best epoch 28\n",
            "Epoch 028: | Train Loss: 0.65968271 | Val Loss: 0.65798741 | Train Acc: 0.76576147| Val Acc: 0.76798187\n",
            "best epoch 29\n",
            "Epoch 029: | Train Loss: 0.65902185 | Val Loss: 0.65730135 | Train Acc: 0.76599005| Val Acc: 0.76815747\n",
            "best epoch 30\n",
            "Epoch 030: | Train Loss: 0.65838251 | Val Loss: 0.65663987 | Train Acc: 0.76617624| Val Acc: 0.76822407\n",
            "best epoch 31\n",
            "Epoch 031: | Train Loss: 0.65776434 | Val Loss: 0.65600245 | Train Acc: 0.76636395| Val Acc: 0.76843600\n",
            "best epoch 32\n",
            "Epoch 032: | Train Loss: 0.65716679 | Val Loss: 0.65538848 | Train Acc: 0.76652743| Val Acc: 0.76859343\n",
            "best epoch 33\n",
            "Epoch 033: | Train Loss: 0.65658934 | Val Loss: 0.65479708 | Train Acc: 0.76670000| Val Acc: 0.76865398\n",
            "best epoch 34\n",
            "Epoch 034: | Train Loss: 0.65603124 | Val Loss: 0.65422734 | Train Acc: 0.76687257| Val Acc: 0.76882352\n",
            "best epoch 35\n",
            "Epoch 035: | Train Loss: 0.65549169 | Val Loss: 0.65367846 | Train Acc: 0.76704514| Val Acc: 0.76904150\n",
            "best epoch 36\n",
            "Epoch 036: | Train Loss: 0.65496991 | Val Loss: 0.65314904 | Train Acc: 0.76721771| Val Acc: 0.76916260\n",
            "best epoch 37\n",
            "Epoch 037: | Train Loss: 0.65446502 | Val Loss: 0.65263822 | Train Acc: 0.76751894| Val Acc: 0.76932003\n",
            "best epoch 38\n",
            "Epoch 038: | Train Loss: 0.65397634 | Val Loss: 0.65214515 | Train Acc: 0.76770816| Val Acc: 0.76953801\n",
            "best epoch 39\n",
            "Epoch 039: | Train Loss: 0.65350315 | Val Loss: 0.65166878 | Train Acc: 0.76787316| Val Acc: 0.76983471\n",
            "best epoch 40\n",
            "Epoch 040: | Train Loss: 0.65304490 | Val Loss: 0.65120818 | Train Acc: 0.76804270| Val Acc: 0.76995581\n",
            "best epoch 41\n",
            "Epoch 041: | Train Loss: 0.65260100 | Val Loss: 0.65076278 | Train Acc: 0.76823041| Val Acc: 0.77013141\n",
            "best epoch 42\n",
            "Epoch 042: | Train Loss: 0.65217090 | Val Loss: 0.65033181 | Train Acc: 0.76838633| Val Acc: 0.77025251\n",
            "best epoch 43\n",
            "Epoch 043: | Train Loss: 0.65175412 | Val Loss: 0.64991455 | Train Acc: 0.76850137| Val Acc: 0.77042205\n",
            "best epoch 44\n",
            "Epoch 044: | Train Loss: 0.65135025 | Val Loss: 0.64951068 | Train Acc: 0.76862853| Val Acc: 0.77051287\n",
            "best epoch 45\n",
            "Epoch 045: | Train Loss: 0.65095882 | Val Loss: 0.64911939 | Train Acc: 0.76879958| Val Acc: 0.77068241\n",
            "best epoch 46\n",
            "Epoch 046: | Train Loss: 0.65057950 | Val Loss: 0.64874046 | Train Acc: 0.76892976| Val Acc: 0.77078535\n",
            "best epoch 47\n",
            "Epoch 047: | Train Loss: 0.65021189 | Val Loss: 0.64837326 | Train Acc: 0.76908720| Val Acc: 0.77093067\n",
            "best epoch 48\n",
            "Epoch 048: | Train Loss: 0.64985556 | Val Loss: 0.64801752 | Train Acc: 0.76921738| Val Acc: 0.77100938\n",
            "best epoch 49\n",
            "Epoch 049: | Train Loss: 0.64951024 | Val Loss: 0.64767253 | Train Acc: 0.76932183| Val Acc: 0.77116076\n",
            "best epoch 50\n",
            "Epoch 050: | Train Loss: 0.64917560 | Val Loss: 0.64733829 | Train Acc: 0.76947623| Val Acc: 0.77128792\n",
            "best epoch 51\n",
            "Epoch 051: | Train Loss: 0.64885131 | Val Loss: 0.64701428 | Train Acc: 0.76955040| Val Acc: 0.77146957\n",
            "best epoch 52\n",
            "Epoch 052: | Train Loss: 0.64853702 | Val Loss: 0.64670028 | Train Acc: 0.76963063| Val Acc: 0.77150590\n",
            "best epoch 53\n",
            "Epoch 053: | Train Loss: 0.64823240 | Val Loss: 0.64639581 | Train Acc: 0.76972146| Val Acc: 0.77163305\n",
            "best epoch 54\n",
            "Epoch 054: | Train Loss: 0.64793699 | Val Loss: 0.64610055 | Train Acc: 0.76980320| Val Acc: 0.77177837\n",
            "best epoch 55\n",
            "Epoch 055: | Train Loss: 0.64765032 | Val Loss: 0.64581418 | Train Acc: 0.76990160| Val Acc: 0.77189342\n",
            "best epoch 56\n",
            "Epoch 056: | Train Loss: 0.64737204 | Val Loss: 0.64553640 | Train Acc: 0.77000605| Val Acc: 0.77202663\n",
            "best epoch 57\n",
            "Epoch 057: | Train Loss: 0.64710165 | Val Loss: 0.64526681 | Train Acc: 0.77008476| Val Acc: 0.77208112\n",
            "best epoch 58\n",
            "Epoch 058: | Train Loss: 0.64683875 | Val Loss: 0.64500501 | Train Acc: 0.77018013| Val Acc: 0.77209929\n",
            "best epoch 59\n",
            "Epoch 059: | Train Loss: 0.64658295 | Val Loss: 0.64475093 | Train Acc: 0.77025582| Val Acc: 0.77206901\n",
            "best epoch 60\n",
            "Epoch 060: | Train Loss: 0.64633383 | Val Loss: 0.64450402 | Train Acc: 0.77035572| Val Acc: 0.77209929\n",
            "best epoch 61\n",
            "Epoch 061: | Train Loss: 0.64609107 | Val Loss: 0.64426383 | Train Acc: 0.77041325| Val Acc: 0.77217801\n",
            "best epoch 62\n",
            "Epoch 062: | Train Loss: 0.64585435 | Val Loss: 0.64402994 | Train Acc: 0.77050407| Val Acc: 0.77219617\n",
            "best epoch 63\n",
            "Epoch 063: | Train Loss: 0.64562333 | Val Loss: 0.64380150 | Train Acc: 0.77055403| Val Acc: 0.77228700\n",
            "best epoch 64\n",
            "Epoch 064: | Train Loss: 0.64539772 | Val Loss: 0.64357854 | Train Acc: 0.77060549| Val Acc: 0.77240204\n",
            "best epoch 65\n",
            "Epoch 065: | Train Loss: 0.64517726 | Val Loss: 0.64336038 | Train Acc: 0.77069632| Val Acc: 0.77240204\n",
            "best epoch 66\n",
            "Epoch 066: | Train Loss: 0.64496166 | Val Loss: 0.64314712 | Train Acc: 0.77074173| Val Acc: 0.77249892\n",
            "best epoch 67\n",
            "Epoch 067: | Train Loss: 0.64475074 | Val Loss: 0.64293827 | Train Acc: 0.77082347| Val Acc: 0.77253525\n",
            "best epoch 68\n",
            "Epoch 068: | Train Loss: 0.64454424 | Val Loss: 0.64273372 | Train Acc: 0.77089159| Val Acc: 0.77260186\n",
            "best epoch 69\n",
            "Epoch 069: | Train Loss: 0.64434199 | Val Loss: 0.64253321 | Train Acc: 0.77099756| Val Acc: 0.77268057\n",
            "best epoch 70\n",
            "Epoch 070: | Train Loss: 0.64414377 | Val Loss: 0.64233649 | Train Acc: 0.77107476| Val Acc: 0.77269874\n",
            "best epoch 71\n",
            "Epoch 071: | Train Loss: 0.64394943 | Val Loss: 0.64214356 | Train Acc: 0.77110655| Val Acc: 0.77273507\n",
            "best epoch 72\n",
            "Epoch 072: | Train Loss: 0.64375880 | Val Loss: 0.64195428 | Train Acc: 0.77118072| Val Acc: 0.77281984\n",
            "best epoch 73\n",
            "Epoch 073: | Train Loss: 0.64357170 | Val Loss: 0.64176848 | Train Acc: 0.77125490| Val Acc: 0.77285011\n",
            "best epoch 74\n",
            "Epoch 074: | Train Loss: 0.64338805 | Val Loss: 0.64158596 | Train Acc: 0.77130485| Val Acc: 0.77293488\n",
            "best epoch 75\n",
            "Epoch 075: | Train Loss: 0.64320766 | Val Loss: 0.64140685 | Train Acc: 0.77136237| Val Acc: 0.77303176\n",
            "best epoch 76\n",
            "Epoch 076: | Train Loss: 0.64303047 | Val Loss: 0.64123074 | Train Acc: 0.77141081| Val Acc: 0.77311653\n",
            "best epoch 77\n",
            "Epoch 077: | Train Loss: 0.64285631 | Val Loss: 0.64105780 | Train Acc: 0.77144866| Val Acc: 0.77313470\n",
            "best epoch 78\n",
            "Epoch 078: | Train Loss: 0.64268511 | Val Loss: 0.64088776 | Train Acc: 0.77148953| Val Acc: 0.77315892\n",
            "best epoch 79\n",
            "Epoch 079: | Train Loss: 0.64251672 | Val Loss: 0.64072050 | Train Acc: 0.77154402| Val Acc: 0.77313470\n",
            "best epoch 80\n",
            "Epoch 080: | Train Loss: 0.64235106 | Val Loss: 0.64055626 | Train Acc: 0.77159852| Val Acc: 0.77317103\n",
            "best epoch 81\n",
            "Epoch 081: | Train Loss: 0.64218804 | Val Loss: 0.64039459 | Train Acc: 0.77162879| Val Acc: 0.77320736\n",
            "best epoch 82\n",
            "Epoch 082: | Train Loss: 0.64202759 | Val Loss: 0.64023538 | Train Acc: 0.77166966| Val Acc: 0.77329213\n",
            "best epoch 83\n",
            "Epoch 083: | Train Loss: 0.64186959 | Val Loss: 0.64007890 | Train Acc: 0.77172265| Val Acc: 0.77334057\n",
            "best epoch 84\n",
            "Epoch 084: | Train Loss: 0.64171397 | Val Loss: 0.63992466 | Train Acc: 0.77177260| Val Acc: 0.77345562\n",
            "best epoch 85\n",
            "Epoch 085: | Train Loss: 0.64156066 | Val Loss: 0.63977290 | Train Acc: 0.77180893| Val Acc: 0.77350406\n",
            "best epoch 86\n",
            "Epoch 086: | Train Loss: 0.64140961 | Val Loss: 0.63962340 | Train Acc: 0.77184829| Val Acc: 0.77350406\n",
            "best epoch 87\n",
            "Epoch 087: | Train Loss: 0.64126071 | Val Loss: 0.63947608 | Train Acc: 0.77186343| Val Acc: 0.77357066\n",
            "best epoch 88\n",
            "Epoch 088: | Train Loss: 0.64111392 | Val Loss: 0.63933093 | Train Acc: 0.77189673| Val Acc: 0.77358883\n",
            "best epoch 89\n",
            "Epoch 089: | Train Loss: 0.64096916 | Val Loss: 0.63918789 | Train Acc: 0.77196485| Val Acc: 0.77355250\n",
            "best epoch 90\n",
            "Epoch 090: | Train Loss: 0.64082637 | Val Loss: 0.63904695 | Train Acc: 0.77201177| Val Acc: 0.77358277\n",
            "best epoch 91\n",
            "Epoch 091: | Train Loss: 0.64068551 | Val Loss: 0.63890789 | Train Acc: 0.77204810| Val Acc: 0.77363121\n",
            "best epoch 92\n",
            "Epoch 092: | Train Loss: 0.64054654 | Val Loss: 0.63877080 | Train Acc: 0.77211017| Val Acc: 0.77367360\n",
            "best epoch 93\n",
            "Epoch 093: | Train Loss: 0.64040937 | Val Loss: 0.63863549 | Train Acc: 0.77217375| Val Acc: 0.77371598\n",
            "best epoch 94\n",
            "Epoch 094: | Train Loss: 0.64027395 | Val Loss: 0.63850202 | Train Acc: 0.77221462| Val Acc: 0.77378864\n",
            "best epoch 95\n",
            "Epoch 095: | Train Loss: 0.64014028 | Val Loss: 0.63837029 | Train Acc: 0.77224489| Val Acc: 0.77375837\n",
            "best epoch 96\n",
            "Epoch 096: | Train Loss: 0.64000827 | Val Loss: 0.63824026 | Train Acc: 0.77228728| Val Acc: 0.77381892\n",
            "best epoch 97\n",
            "Epoch 097: | Train Loss: 0.63987788 | Val Loss: 0.63811180 | Train Acc: 0.77236145| Val Acc: 0.77385525\n",
            "best epoch 98\n",
            "Epoch 098: | Train Loss: 0.63974910 | Val Loss: 0.63798521 | Train Acc: 0.77239475| Val Acc: 0.77388552\n",
            "best epoch 99\n",
            "Epoch 099: | Train Loss: 0.63962189 | Val Loss: 0.63785997 | Train Acc: 0.77243679| Val Acc: 0.77387341\n",
            "best epoch 100\n",
            "Epoch 100: | Train Loss: 0.63949621 | Val Loss: 0.63773646 | Train Acc: 0.77246252| Val Acc: 0.77392185\n",
            "best epoch 101\n",
            "Epoch 101: | Train Loss: 0.63937201 | Val Loss: 0.63761423 | Train Acc: 0.77250340| Val Acc: 0.77395213\n",
            "best epoch 102\n",
            "Epoch 102: | Train Loss: 0.63924927 | Val Loss: 0.63749357 | Train Acc: 0.77254275| Val Acc: 0.77397029\n",
            "best epoch 103\n",
            "Epoch 103: | Train Loss: 0.63912795 | Val Loss: 0.63737442 | Train Acc: 0.77256546| Val Acc: 0.77401873\n",
            "best epoch 104\n",
            "Epoch 104: | Train Loss: 0.63900805 | Val Loss: 0.63725654 | Train Acc: 0.77257454| Val Acc: 0.77401873\n",
            "best epoch 105\n",
            "Epoch 105: | Train Loss: 0.63888951 | Val Loss: 0.63714000 | Train Acc: 0.77260784| Val Acc: 0.77407323\n",
            "best epoch 106\n",
            "Epoch 106: | Train Loss: 0.63877228 | Val Loss: 0.63702485 | Train Acc: 0.77261576| Val Acc: 0.77409745\n",
            "best epoch 107\n",
            "Epoch 107: | Train Loss: 0.63865642 | Val Loss: 0.63691095 | Train Acc: 0.77264452| Val Acc: 0.77415800\n",
            "best epoch 108\n",
            "Epoch 108: | Train Loss: 0.63854184 | Val Loss: 0.63679830 | Train Acc: 0.77267631| Val Acc: 0.77423066\n",
            "best epoch 109\n",
            "Epoch 109: | Train Loss: 0.63842850 | Val Loss: 0.63668678 | Train Acc: 0.77268842| Val Acc: 0.77425488\n",
            "best epoch 110\n",
            "Epoch 110: | Train Loss: 0.63831641 | Val Loss: 0.63657665 | Train Acc: 0.77274292| Val Acc: 0.77429727\n",
            "best epoch 111\n",
            "Epoch 111: | Train Loss: 0.63820552 | Val Loss: 0.63646754 | Train Acc: 0.77279136| Val Acc: 0.77437598\n",
            "best epoch 112\n",
            "Epoch 112: | Train Loss: 0.63809583 | Val Loss: 0.63635948 | Train Acc: 0.77281104| Val Acc: 0.77439415\n",
            "best epoch 113\n",
            "Epoch 113: | Train Loss: 0.63798731 | Val Loss: 0.63625267 | Train Acc: 0.77284888| Val Acc: 0.77445470\n",
            "best epoch 114\n",
            "Epoch 114: | Train Loss: 0.63787992 | Val Loss: 0.63614701 | Train Acc: 0.77287916| Val Acc: 0.77450919\n",
            "best epoch 115\n",
            "Epoch 115: | Train Loss: 0.63777366 | Val Loss: 0.63604225 | Train Acc: 0.77290338| Val Acc: 0.77457580\n",
            "best epoch 116\n",
            "Epoch 116: | Train Loss: 0.63766850 | Val Loss: 0.63593850 | Train Acc: 0.77291095| Val Acc: 0.77462424\n",
            "best epoch 117\n",
            "Epoch 117: | Train Loss: 0.63756440 | Val Loss: 0.63583580 | Train Acc: 0.77293668| Val Acc: 0.77464846\n",
            "best epoch 118\n",
            "Epoch 118: | Train Loss: 0.63746137 | Val Loss: 0.63573408 | Train Acc: 0.77295333| Val Acc: 0.77465451\n",
            "best epoch 119\n",
            "Epoch 119: | Train Loss: 0.63735938 | Val Loss: 0.63563337 | Train Acc: 0.77298512| Val Acc: 0.77469690\n",
            "best epoch 120\n",
            "Epoch 120: | Train Loss: 0.63725840 | Val Loss: 0.63553353 | Train Acc: 0.77301388| Val Acc: 0.77466662\n",
            "best epoch 121\n",
            "Epoch 121: | Train Loss: 0.63715843 | Val Loss: 0.63543464 | Train Acc: 0.77303961| Val Acc: 0.77466057\n",
            "best epoch 122\n",
            "Epoch 122: | Train Loss: 0.63705942 | Val Loss: 0.63533657 | Train Acc: 0.77308351| Val Acc: 0.77466057\n",
            "best epoch 123\n",
            "Epoch 123: | Train Loss: 0.63696139 | Val Loss: 0.63523934 | Train Acc: 0.77311530| Val Acc: 0.77469084\n",
            "best epoch 124\n",
            "Epoch 124: | Train Loss: 0.63686431 | Val Loss: 0.63514312 | Train Acc: 0.77313650| Val Acc: 0.77471506\n",
            "best epoch 125\n",
            "Epoch 125: | Train Loss: 0.63676813 | Val Loss: 0.63504761 | Train Acc: 0.77316828| Val Acc: 0.77474534\n",
            "best epoch 126\n",
            "Epoch 126: | Train Loss: 0.63667288 | Val Loss: 0.63495293 | Train Acc: 0.77321218| Val Acc: 0.77479378\n",
            "best epoch 127\n",
            "Epoch 127: | Train Loss: 0.63657851 | Val Loss: 0.63485903 | Train Acc: 0.77323035| Val Acc: 0.77481800\n",
            "best epoch 128\n",
            "Epoch 128: | Train Loss: 0.63648503 | Val Loss: 0.63476592 | Train Acc: 0.77324851| Val Acc: 0.77487249\n",
            "best epoch 129\n",
            "Epoch 129: | Train Loss: 0.63639243 | Val Loss: 0.63467355 | Train Acc: 0.77325457| Val Acc: 0.77489671\n",
            "best epoch 130\n",
            "Epoch 130: | Train Loss: 0.63630066 | Val Loss: 0.63458205 | Train Acc: 0.77327879| Val Acc: 0.77493304\n",
            "best epoch 131\n",
            "Epoch 131: | Train Loss: 0.63620974 | Val Loss: 0.63449123 | Train Acc: 0.77330906| Val Acc: 0.77496937\n",
            "best epoch 132\n",
            "Epoch 132: | Train Loss: 0.63611962 | Val Loss: 0.63440102 | Train Acc: 0.77334842| Val Acc: 0.77496332\n",
            "best epoch 133\n",
            "Epoch 133: | Train Loss: 0.63603033 | Val Loss: 0.63431152 | Train Acc: 0.77337870| Val Acc: 0.77493910\n",
            "best epoch 134\n",
            "Epoch 134: | Train Loss: 0.63594182 | Val Loss: 0.63422280 | Train Acc: 0.77339232| Val Acc: 0.77498148\n",
            "best epoch 135\n",
            "Epoch 135: | Train Loss: 0.63585409 | Val Loss: 0.63413470 | Train Acc: 0.77340292| Val Acc: 0.77506020\n",
            "best epoch 136\n",
            "Epoch 136: | Train Loss: 0.63576712 | Val Loss: 0.63404718 | Train Acc: 0.77341957| Val Acc: 0.77515708\n",
            "best epoch 137\n",
            "Epoch 137: | Train Loss: 0.63568092 | Val Loss: 0.63396040 | Train Acc: 0.77343925| Val Acc: 0.77519341\n",
            "best epoch 138\n",
            "Epoch 138: | Train Loss: 0.63559547 | Val Loss: 0.63387422 | Train Acc: 0.77344682| Val Acc: 0.77520552\n",
            "best epoch 139\n",
            "Epoch 139: | Train Loss: 0.63551073 | Val Loss: 0.63378867 | Train Acc: 0.77348466| Val Acc: 0.77520552\n",
            "best epoch 140\n",
            "Epoch 140: | Train Loss: 0.63542676 | Val Loss: 0.63370381 | Train Acc: 0.77348617| Val Acc: 0.77524185\n",
            "best epoch 141\n",
            "Epoch 141: | Train Loss: 0.63534346 | Val Loss: 0.63361958 | Train Acc: 0.77351645| Val Acc: 0.77525396\n",
            "best epoch 142\n",
            "Epoch 142: | Train Loss: 0.63526084 | Val Loss: 0.63353581 | Train Acc: 0.77353915| Val Acc: 0.77527818\n",
            "best epoch 143\n",
            "Epoch 143: | Train Loss: 0.63517894 | Val Loss: 0.63345273 | Train Acc: 0.77358003| Val Acc: 0.77530240\n",
            "best epoch 144\n",
            "Epoch 144: | Train Loss: 0.63509773 | Val Loss: 0.63337023 | Train Acc: 0.77359365| Val Acc: 0.77532056\n",
            "best epoch 145\n",
            "Epoch 145: | Train Loss: 0.63501715 | Val Loss: 0.63328819 | Train Acc: 0.77362998| Val Acc: 0.77530845\n",
            "best epoch 146\n",
            "Epoch 146: | Train Loss: 0.63493728 | Val Loss: 0.63320677 | Train Acc: 0.77365269| Val Acc: 0.77529029\n",
            "best epoch 147\n",
            "Epoch 147: | Train Loss: 0.63485805 | Val Loss: 0.63312593 | Train Acc: 0.77367237| Val Acc: 0.77530240\n",
            "best epoch 148\n",
            "Epoch 148: | Train Loss: 0.63477945 | Val Loss: 0.63304555 | Train Acc: 0.77368448| Val Acc: 0.77534479\n",
            "best epoch 149\n",
            "Epoch 149: | Train Loss: 0.63470147 | Val Loss: 0.63296564 | Train Acc: 0.77370567| Val Acc: 0.77538112\n",
            "best epoch 150\n",
            "Epoch 150: | Train Loss: 0.63462411 | Val Loss: 0.63288654 | Train Acc: 0.77373897| Val Acc: 0.77539323\n",
            "best epoch 151\n",
            "Epoch 151: | Train Loss: 0.63454738 | Val Loss: 0.63280781 | Train Acc: 0.77375865| Val Acc: 0.77543561\n",
            "best epoch 152\n",
            "Epoch 152: | Train Loss: 0.63447125 | Val Loss: 0.63272951 | Train Acc: 0.77375714| Val Acc: 0.77544167\n",
            "best epoch 153\n",
            "Epoch 153: | Train Loss: 0.63439573 | Val Loss: 0.63265190 | Train Acc: 0.77376470| Val Acc: 0.77544772\n",
            "best epoch 154\n",
            "Epoch 154: | Train Loss: 0.63432079 | Val Loss: 0.63257462 | Train Acc: 0.77377530| Val Acc: 0.77542956\n",
            "best epoch 155\n",
            "Epoch 155: | Train Loss: 0.63424643 | Val Loss: 0.63249793 | Train Acc: 0.77379649| Val Acc: 0.77544167\n",
            "best epoch 156\n",
            "Epoch 156: | Train Loss: 0.63417265 | Val Loss: 0.63242167 | Train Acc: 0.77382374| Val Acc: 0.77547194\n",
            "best epoch 157\n",
            "Epoch 157: | Train Loss: 0.63409941 | Val Loss: 0.63234596 | Train Acc: 0.77382980| Val Acc: 0.77545983\n",
            "best epoch 158\n",
            "Epoch 158: | Train Loss: 0.63402673 | Val Loss: 0.63227073 | Train Acc: 0.77384645| Val Acc: 0.77545378\n",
            "best epoch 159\n",
            "Epoch 159: | Train Loss: 0.63395461 | Val Loss: 0.63219603 | Train Acc: 0.77385250| Val Acc: 0.77552644\n",
            "best epoch 160\n",
            "Epoch 160: | Train Loss: 0.63388300 | Val Loss: 0.63212168 | Train Acc: 0.77385856| Val Acc: 0.77552644\n",
            "best epoch 161\n",
            "Epoch 161: | Train Loss: 0.63381194 | Val Loss: 0.63204786 | Train Acc: 0.77388429| Val Acc: 0.77559304\n",
            "best epoch 162\n",
            "Epoch 162: | Train Loss: 0.63374142 | Val Loss: 0.63197455 | Train Acc: 0.77389337| Val Acc: 0.77564754\n",
            "best epoch 163\n",
            "Epoch 163: | Train Loss: 0.63367140 | Val Loss: 0.63190174 | Train Acc: 0.77391911| Val Acc: 0.77568387\n",
            "best epoch 164\n",
            "Epoch 164: | Train Loss: 0.63360190 | Val Loss: 0.63182926 | Train Acc: 0.77394333| Val Acc: 0.77571414\n",
            "best epoch 165\n",
            "Epoch 165: | Train Loss: 0.63353288 | Val Loss: 0.63175721 | Train Acc: 0.77396906| Val Acc: 0.77572625\n",
            "best epoch 166\n",
            "Epoch 166: | Train Loss: 0.63346439 | Val Loss: 0.63168569 | Train Acc: 0.77398874| Val Acc: 0.77573836\n",
            "best epoch 167\n",
            "Epoch 167: | Train Loss: 0.63339637 | Val Loss: 0.63161461 | Train Acc: 0.77400085| Val Acc: 0.77576864\n",
            "best epoch 168\n",
            "Epoch 168: | Train Loss: 0.63332884 | Val Loss: 0.63154401 | Train Acc: 0.77401599| Val Acc: 0.77578680\n",
            "best epoch 169\n",
            "Epoch 169: | Train Loss: 0.63326180 | Val Loss: 0.63147395 | Train Acc: 0.77401750| Val Acc: 0.77580497\n",
            "best epoch 170\n",
            "Epoch 170: | Train Loss: 0.63319522 | Val Loss: 0.63140415 | Train Acc: 0.77404929| Val Acc: 0.77585341\n",
            "best epoch 171\n",
            "Epoch 171: | Train Loss: 0.63312910 | Val Loss: 0.63133482 | Train Acc: 0.77406594| Val Acc: 0.77584130\n",
            "best epoch 172\n",
            "Epoch 172: | Train Loss: 0.63306345 | Val Loss: 0.63126593 | Train Acc: 0.77408259| Val Acc: 0.77580497\n",
            "best epoch 173\n",
            "Epoch 173: | Train Loss: 0.63299827 | Val Loss: 0.63119745 | Train Acc: 0.77410379| Val Acc: 0.77580497\n",
            "best epoch 174\n",
            "Epoch 174: | Train Loss: 0.63293350 | Val Loss: 0.63112952 | Train Acc: 0.77412195| Val Acc: 0.77582313\n",
            "best epoch 175\n",
            "Epoch 175: | Train Loss: 0.63286921 | Val Loss: 0.63106186 | Train Acc: 0.77414617| Val Acc: 0.77587157\n",
            "best epoch 176\n",
            "Epoch 176: | Train Loss: 0.63280535 | Val Loss: 0.63099463 | Train Acc: 0.77415525| Val Acc: 0.77585946\n",
            "best epoch 177\n",
            "Epoch 177: | Train Loss: 0.63274192 | Val Loss: 0.63092785 | Train Acc: 0.77418250| Val Acc: 0.77587763\n",
            "best epoch 178\n",
            "Epoch 178: | Train Loss: 0.63267890 | Val Loss: 0.63086140 | Train Acc: 0.77419158| Val Acc: 0.77593212\n",
            "best epoch 179\n",
            "Epoch 179: | Train Loss: 0.63261632 | Val Loss: 0.63079557 | Train Acc: 0.77420218| Val Acc: 0.77594423\n",
            "best epoch 180\n",
            "Epoch 180: | Train Loss: 0.63255415 | Val Loss: 0.63072994 | Train Acc: 0.77421126| Val Acc: 0.77599267\n",
            "best epoch 181\n",
            "Epoch 181: | Train Loss: 0.63249236 | Val Loss: 0.63066479 | Train Acc: 0.77422337| Val Acc: 0.77601689\n",
            "best epoch 182\n",
            "Epoch 182: | Train Loss: 0.63243100 | Val Loss: 0.63060010 | Train Acc: 0.77423397| Val Acc: 0.77603506\n",
            "best epoch 183\n",
            "Epoch 183: | Train Loss: 0.63237004 | Val Loss: 0.63053575 | Train Acc: 0.77425668| Val Acc: 0.77607744\n",
            "best epoch 184\n",
            "Epoch 184: | Train Loss: 0.63230949 | Val Loss: 0.63047184 | Train Acc: 0.77426424| Val Acc: 0.77610166\n",
            "best epoch 185\n",
            "Epoch 185: | Train Loss: 0.63224931 | Val Loss: 0.63040821 | Train Acc: 0.77429149| Val Acc: 0.77610772\n",
            "best epoch 186\n",
            "Epoch 186: | Train Loss: 0.63218951 | Val Loss: 0.63034493 | Train Acc: 0.77430209| Val Acc: 0.77610166\n",
            "best epoch 187\n",
            "Epoch 187: | Train Loss: 0.63213007 | Val Loss: 0.63028222 | Train Acc: 0.77429906| Val Acc: 0.77615010\n",
            "best epoch 188\n",
            "Epoch 188: | Train Loss: 0.63207102 | Val Loss: 0.63021981 | Train Acc: 0.77432177| Val Acc: 0.77615010\n",
            "best epoch 189\n",
            "Epoch 189: | Train Loss: 0.63201235 | Val Loss: 0.63015774 | Train Acc: 0.77433539| Val Acc: 0.77613799\n",
            "best epoch 190\n",
            "Epoch 190: | Train Loss: 0.63195406 | Val Loss: 0.63009619 | Train Acc: 0.77434750| Val Acc: 0.77613194\n",
            "best epoch 191\n",
            "Epoch 191: | Train Loss: 0.63189612 | Val Loss: 0.63003474 | Train Acc: 0.77436112| Val Acc: 0.77614405\n",
            "best epoch 192\n",
            "Epoch 192: | Train Loss: 0.63183852 | Val Loss: 0.62997392 | Train Acc: 0.77437929| Val Acc: 0.77611377\n",
            "best epoch 193\n",
            "Epoch 193: | Train Loss: 0.63178128 | Val Loss: 0.62991334 | Train Acc: 0.77441108| Val Acc: 0.77611983\n",
            "best epoch 194\n",
            "Epoch 194: | Train Loss: 0.63172438 | Val Loss: 0.62985322 | Train Acc: 0.77441259| Val Acc: 0.77616827\n",
            "best epoch 195\n",
            "Epoch 195: | Train Loss: 0.63166782 | Val Loss: 0.62979331 | Train Acc: 0.77442924| Val Acc: 0.77622276\n",
            "best epoch 196\n",
            "Epoch 196: | Train Loss: 0.63161162 | Val Loss: 0.62973376 | Train Acc: 0.77443076| Val Acc: 0.77625304\n",
            "best epoch 197\n",
            "Epoch 197: | Train Loss: 0.63155572 | Val Loss: 0.62967458 | Train Acc: 0.77443227| Val Acc: 0.77625304\n",
            "best epoch 198\n",
            "Epoch 198: | Train Loss: 0.63150017 | Val Loss: 0.62961575 | Train Acc: 0.77446255| Val Acc: 0.77626515\n",
            "best epoch 199\n",
            "Epoch 199: | Train Loss: 0.63144493 | Val Loss: 0.62955738 | Train Acc: 0.77447617| Val Acc: 0.77630734\n",
            "best epoch 200\n",
            "Epoch 200: | Train Loss: 0.63139002 | Val Loss: 0.62949922 | Train Acc: 0.77449888| Val Acc: 0.77630734\n",
            "\n",
            "Model - Post-training AnfisNet(\n",
            "  Rule  0: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.3938518762588501], [0.6276597380638123], [0.7912284135818481], [0.0], [0.8803654313087463], [0.9999999403953552]]\n",
            "  Rule  1: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.4061460494995117], [0.021155238151550293], [0.9999999403953552], [0.3376842141151428], [0.0], [0.010985612869262695]]\n",
            "  Rule  2: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[1.0], [0.8803039789199829], [0.6304720640182495], [0.6494996547698975], [0.017185568809509277], [0.0]]\n",
            "  Rule  3: IF x0 is mf0 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.9999998807907104], [0.0], [0.632278323173523], [0.9982949495315552], [0.15389490127563477], [0.2787179946899414]]\n",
            "  Rule  4: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.8263182640075684], [0.9999999403953552], [0.0], [0.37036168575286865], [0.3191702365875244], [0.8059712648391724]]\n",
            "  Rule  5: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.4958880543708801], [1.0], [0.0], [0.17070811986923218], [0.5495052337646484], [0.9542930126190186]]\n",
            "  Rule  6: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.41541650891304016], [0.7569524645805359], [1.0], [0.0], [0.2154286503791809], [0.7322499752044678]]\n",
            "  Rule  7: IF x0 is mf0 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[1.0], [0.5681573152542114], [0.7214386463165283], [0.0], [0.6068897247314453], [0.9976263046264648]]\n",
            "  Rule  8: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[1.0], [0.5821987986564636], [0.0], [0.4013509154319763], [0.06115180253982544], [0.6118491291999817]]\n",
            "  Rule  9: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.644734263420105], [0.0], [0.6992989778518677], [0.5770497918128967], [0.13652744889259338], [1.0]]\n",
            "  Rule 10: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.7706473469734192], [0.0], [0.5871262550354004], [0.9763404726982117], [1.0], [0.981413722038269]]\n",
            "  Rule 11: IF x0 is mf0 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.2679799795150757], [0.5633069276809692], [0.0], [1.0], [0.6404682397842407], [0.3818366825580597]]\n",
            "  Rule 12: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[1.0], [0.6251075267791748], [0.0], [0.34724655747413635], [0.19996613264083862], [0.6093441247940063]]\n",
            "  Rule 13: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[1.0], [0.0], [0.3041744828224182], [0.36695486307144165], [0.18308499455451965], [0.8390446305274963]]\n",
            "  Rule 14: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.9999999403953552], [0.024150073528289795], [0.0], [0.3316308259963989], [0.47584986686706543], [0.476459801197052]]\n",
            "  Rule 15: IF x0 is mf0 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.9999998807907104], [0.35819709300994873], [0.0], [0.5330104827880859], [0.346707284450531], [0.5054845213890076]]\n",
            "  Rule 16: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.0067816972732543945], [1.0], [0.4304746389389038], [0.44089269638061523], [0.6827046275138855]]\n",
            "  Rule 17: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.28558415174484253], [0.6971250772476196], [0.5220127105712891], [0.5407401323318481], [1.0]]\n",
            "  Rule 18: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.20360741019248962], [0.14088594913482666], [0.7856382131576538], [0.9999999403953552], [0.944753110408783]]\n",
            "  Rule 19: IF x0 is mf0 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.8998851776123047], [0.9048458337783813], [1.0], [0.5726343989372253], [0.9934917092323303]]\n",
            "  Rule 20: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.7963682413101196], [0.27331578731536865], [0.8759781122207642], [1.0], [0.0], [0.6834890246391296]]\n",
            "  Rule 21: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.7402274012565613], [0.8264670372009277], [0.9717806577682495], [0.0], [0.6770265698432922]]\n",
            "  Rule 22: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.23149795830249786], [0.5242477655410767], [0.3614444434642792], [0.2873045802116394], [0.0], [1.0000001192092896]]\n",
            "  Rule 23: IF x0 is mf0 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.025711655616760254], [0.62874835729599], [0.536472499370575], [0.0], [1.0], [0.652875542640686]]\n",
            "  Rule 24: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.9634643197059631], [0.49709662795066833], [0.6499996185302734], [0.9999999403953552], [0.0], [0.29815247654914856]]\n",
            "  Rule 25: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.5687589645385742], [0.47671911120414734], [0.9999999403953552], [0.5431123375892639], [0.142327219247818], [0.0]]\n",
            "  Rule 26: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.19333192706108093], [0.0], [1.0], [0.10885077714920044], [0.1814265102148056], [0.232552632689476]]\n",
            "  Rule 27: IF x0 is mf0 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.5716989636421204], [0.43692445755004883], [1.0], [0.0], [0.6304211616516113], [0.6432495713233948]]\n",
            "  Rule 28: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[1.0], [0.2469252347946167], [0.7832595705986023], [0.9137098789215088], [0.0], [0.29510942101478577]]\n",
            "  Rule 29: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.9366546869277954], [0.16248229146003723], [1.0], [0.6500248312950134], [0.07550084590911865], [0.0]]\n",
            "  Rule 30: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[1.0], [0.0], [0.7455337047576904], [0.3070458769798279], [0.7300355434417725], [0.5862948894500732]]\n",
            "  Rule 31: IF x0 is mf0 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.9999999403953552], [0.11572864651679993], [0.5178864002227783], [0.0], [0.616938591003418], [0.5623604655265808]]\n",
            "  Rule 32: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.094673752784729], [1.0], [0.7368571758270264], [0.3395700454711914], [0.3632201850414276]]\n",
            "  Rule 33: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.07384169101715088], [0.32382112741470337], [1.0], [0.9453980326652527], [0.37229081988334656], [0.0]]\n",
            "  Rule 34: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.6066485643386841], [0.4176677465438843], [0.626981258392334], [0.9999999403953552], [0.5743904709815979], [0.0]]\n",
            "  Rule 35: IF x0 is mf0 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[1.0], [0.8832693696022034], [0.5307807922363281], [0.9942136406898499], [0.7556515336036682], [0.0]]\n",
            "  Rule 36: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.4764910340309143], [0.29136601090431213], [0.4774306118488312], [1.0], [0.034244000911712646], [0.0]]\n",
            "  Rule 37: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.7185576558113098], [0.6404005885124207], [0.7895154356956482], [1.0], [0.46786177158355713], [0.0]]\n",
            "  Rule 38: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.6537855863571167], [1.0], [0.11595520377159119], [0.5736933946609497], [0.0789574384689331], [0.0]]\n",
            "  Rule 39: IF x0 is mf0 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.8300619125366211], [0.748534083366394], [0.012567222118377686], [1.0], [0.0], [0.6122407913208008]]\n",
            "  Rule 40: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.6021772027015686], [0.43751394748687744], [0.44881632924079895], [1.0], [0.26023098826408386], [0.0]]\n",
            "  Rule 41: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.8496615886688232], [0.9301705360412598], [1.0], [0.7216883897781372], [0.43724533915519714], [0.0]]\n",
            "  Rule 42: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.7522429823875427], [0.9999999403953552], [0.4419958293437958], [0.8837446570396423], [0.07265150547027588], [0.0]]\n",
            "  Rule 43: IF x0 is mf0 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.6677125692367554], [0.8589910864830017], [0.0], [1.0], [0.46292075514793396], [0.7434461712837219]]\n",
            "  Rule 44: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.625586748123169], [0.37026602029800415], [0.6039990186691284], [1.0], [0.40186816453933716], [0.0]]\n",
            "  Rule 45: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.9312090277671814], [0.8458398580551147], [1.0], [0.8172792792320251], [0.4468449354171753], [0.0]]\n",
            "  Rule 46: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.463547945022583], [1.0], [0.5406637191772461], [0.58101487159729], [0.45741233229637146], [0.0]]\n",
            "  Rule 47: IF x0 is mf0 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [1.0], [0.6483889818191528], [0.6680108308792114], [0.7043365240097046], [0.7612719535827637]]\n",
            "  Rule 48: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.06547695398330688], [1.0], [0.6464282274246216], [0.3938659429550171], [0.423317015171051]]\n",
            "  Rule 49: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.2684454321861267], [1.0], [0.8948229551315308], [0.38438189029693604], [0.12183570861816406]]\n",
            "  Rule 50: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.46722787618637085], [0.3525821566581726], [0.4795457124710083], [1.0], [0.5634896159172058], [0.0]]\n",
            "  Rule 51: IF x0 is mf0 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.7743596434593201], [0.9804728031158447], [0.32532790303230286], [1.0], [0.6701700091362], [0.0]]\n",
            "  Rule 52: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.4807237684726715], [0.24215653538703918], [0.4746372699737549], [1.0], [0.020382821559906006], [0.0]]\n",
            "  Rule 53: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.7072688341140747], [0.6594642996788025], [0.8040184378623962], [1.0], [0.4704241156578064], [0.0]]\n",
            "  Rule 54: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.6565817594528198], [0.8924777507781982], [0.0], [1.0], [0.18724456429481506], [0.3060687184333801]]\n",
            "  Rule 55: IF x0 is mf0 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.5794299244880676], [0.31730571389198303], [0.0], [1.0], [0.10094907879829407], [0.6126755475997925]]\n",
            "  Rule 56: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.6218401789665222], [0.43989086151123047], [0.4820384979248047], [1.0], [0.3816036880016327], [0.0]]\n",
            "  Rule 57: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.8085173964500427], [1.0], [0.9522062540054321], [0.77297443151474], [0.44534701108932495], [0.0]]\n",
            "  Rule 58: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.04739457368850708], [0.5648278594017029], [0.014924824237823486], [1.0], [0.0], [0.030334770679473877]]\n",
            "  Rule 59: IF x0 is mf0 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.0], [0.679349958896637], [0.26725295186042786], [1.0], [0.518642783164978], [0.7211973071098328]]\n",
            "  Rule 60: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.6263607740402222], [0.44862449169158936], [0.6869586706161499], [1.0], [0.48248347640037537], [0.0]]\n",
            "  Rule 61: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.8557534217834473], [1.0], [0.9872505068778992], [0.9635148644447327], [0.5139244198799133], [0.0]]\n",
            "  Rule 62: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.9999999403953552], [0.5698301792144775], [0.8902326226234436], [0.58354252576828], [0.5411587953567505]]\n",
            "  Rule 63: IF x0 is mf0 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.0], [1.0], [0.7742683291435242], [0.936493992805481], [0.7092980146408081], [0.9164667725563049]]\n",
            "  Rule 64: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.8268086910247803], [0.8307000398635864], [0.1960766315460205], [1.0], [0.8765052556991577], [0.0]]\n",
            "  Rule 65: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.9999999403953552], [0.29135891795158386], [0.43373605608940125], [0.8841083645820618], [0.6656919717788696], [0.0]]\n",
            "  Rule 66: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[1.0], [0.31420737504959106], [0.0], [0.8196559548377991], [0.5980943441390991], [0.8192148208618164]]\n",
            "  Rule 67: IF x0 is mf1 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.9952489137649536], [0.7550889253616333], [0.5600422620773315], [0.6447564363479614], [1.0], [0.0]]\n",
            "  Rule 68: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.9209383130073547], [1.0], [0.0], [0.5511298179626465], [0.4113372564315796], [0.16969537734985352]]\n",
            "  Rule 69: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.7035914063453674], [0.8348680734634399], [0.5492476224899292], [0.8920761942863464], [0.0]]\n",
            "  Rule 70: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[1.0], [0.9661857485771179], [0.7584561705589294], [0.7378592491149902], [0.6124484539031982], [0.0]]\n",
            "  Rule 71: IF x0 is mf1 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.9235877990722656], [0.6207524538040161], [0.7900912165641785], [1.0], [0.3120485544204712], [0.0]]\n",
            "  Rule 72: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[1.0], [0.6343040466308594], [0.6480530500411987], [0.0], [0.09528854489326477], [0.1293988823890686]]\n",
            "  Rule 73: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.8301021456718445], [1.0], [0.5938360691070557], [0.8573983311653137], [0.4794752597808838], [0.0]]\n",
            "  Rule 74: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.24680861830711365], [0.23078691959381104], [0.5207524299621582], [1.0], [0.8845618963241577], [0.0]]\n",
            "  Rule 75: IF x0 is mf1 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.6377137303352356], [0.8281784653663635], [1.0], [0.4124287962913513], [0.9449678659439087], [0.0]]\n",
            "  Rule 76: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[1.0], [0.7138316631317139], [0.5959869623184204], [0.14712852239608765], [0.21244177222251892], [0.0]]\n",
            "  Rule 77: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.7216704487800598], [0.6509978175163269], [1.0], [0.7344298958778381], [0.5584854483604431], [0.0]]\n",
            "  Rule 78: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.9166463613510132], [0.0], [0.7787987589836121], [0.615959882736206], [1.0], [0.20423460006713867]]\n",
            "  Rule 79: IF x0 is mf1 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[1.0], [0.0], [0.6084961891174316], [0.5408018231391907], [0.6896947622299194], [0.3978534936904907]]\n",
            "  Rule 80: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.6192052960395813], [0.743809700012207], [0.5373183488845825], [0.6847141981124878], [0.9999999403953552]]\n",
            "  Rule 81: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [1.0000001192092896], [0.46636736392974854], [0.6212621927261353], [0.6857423782348633], [0.8088012337684631]]\n",
            "  Rule 82: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.49476611614227295], [1.0], [0.12042981386184692], [0.8626236915588379], [0.9955546855926514]]\n",
            "  Rule 83: IF x0 is mf1 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.4305680990219116], [0.0040929317474365234], [0.3475276827812195], [0.0], [0.36473286151885986], [1.0]]\n",
            "  Rule 84: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.540483832359314], [0.5146679878234863], [0.08354872465133667], [0.0], [0.22494590282440186], [0.9999999403953552]]\n",
            "  Rule 85: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.4988972842693329], [0.2816380262374878], [0.0], [0.09810474514961243], [0.3846876621246338], [0.9999999403953552]]\n",
            "  Rule 86: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.6235495805740356], [0.7226225137710571], [0.0], [0.3895986080169678], [0.6437598466873169], [1.0]]\n",
            "  Rule 87: IF x0 is mf1 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.35498249530792236], [0.6336661577224731], [0.3995048999786377], [0.6572173833847046], [1.0], [0.0]]\n",
            "  Rule 88: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[1.0], [0.7644124031066895], [0.3461165428161621], [0.0], [0.43041670322418213], [0.5988755226135254]]\n",
            "  Rule 89: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.5219441652297974], [1.0000001192092896], [0.0], [0.02838912606239319], [0.266811728477478], [0.608220100402832]]\n",
            "  Rule 90: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.696045458316803], [1.0], [0.0], [0.8899573087692261], [0.15453052520751953], [0.573175311088562]]\n",
            "  Rule 91: IF x0 is mf1 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.4498303532600403], [1.0], [0.38816335797309875], [0.684981107711792], [0.5103102326393127], [0.0]]\n",
            "  Rule 92: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.9999999403953552], [0.4936816096305847], [0.5328289270401001], [0.0], [0.1396651268005371], [0.475315660238266]]\n",
            "  Rule 93: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.9999999403953552], [0.8581619262695312], [0.9466066360473633], [0.7449857592582703], [0.0], [0.9620089530944824]]\n",
            "  Rule 94: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.5846971869468689], [0.0], [1.0], [0.739212155342102], [0.6901827454566956], [0.5850855112075806]]\n",
            "  Rule 95: IF x0 is mf1 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.5135472416877747], [0.0], [1.0], [0.6481899619102478], [0.9452416896820068], [0.7236970663070679]]\n",
            "  Rule 96: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.4799802601337433], [0.41150033473968506], [1.0], [0.4077306091785431], [0.5892118215560913]]\n",
            "  Rule 97: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.2858234643936157], [0.6201029419898987], [1.0], [0.3070036768913269], [0.18901947140693665]]\n",
            "  Rule 98: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.01677069067955017], [0.0], [0.8465838432312012], [1.0], [0.396697998046875], [0.10607936978340149]]\n",
            "  Rule 99: IF x0 is mf1 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.23037365078926086], [0.8560748100280762], [0.8514728546142578], [0.8932926654815674], [1.0]]\n",
            "  Rule 100: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.35434767603874207], [0.31231170892715454], [0.0], [1.0], [0.40060892701148987], [0.5914902687072754]]\n",
            "  Rule 101: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.31033918261528015], [0.0], [1.0], [0.9530175924301147], [0.6716049313545227], [0.814595639705658]]\n",
            "  Rule 102: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.1630084216594696], [0.0], [0.9999999403953552], [0.3796905279159546], [0.6675965785980225], [0.35696062445640564]]\n",
            "  Rule 103: IF x0 is mf1 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.4555707275867462], [0.49164879322052], [0.9999999403953552], [0.40860143303871155], [0.0], [0.865959882736206]]\n",
            "  Rule 104: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.5994870662689209], [0.37853485345840454], [0.0], [1.0], [0.45337843894958496], [0.23973914980888367]]\n",
            "  Rule 105: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[1.0], [0.25746211409568787], [0.697528600692749], [0.41961050033569336], [0.0], [0.3562762439250946]]\n",
            "  Rule 106: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.8638014793395996], [1.0], [0.5097098350524902], [0.5428417325019836], [0.0], [0.39425691962242126]]\n",
            "  Rule 107: IF x0 is mf1 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.7962372899055481], [1.0], [0.0], [0.029478013515472412], [0.10514426231384277], [0.7578585743904114]]\n",
            "  Rule 108: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.6227431893348694], [0.13592419028282166], [0.0], [1.0], [0.048985570669174194], [0.02927607297897339]]\n",
            "  Rule 109: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.8467666506767273], [0.10493144392967224], [0.8562532067298889], [1.0], [0.0], [0.33740270137786865]]\n",
            "  Rule 110: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[1.0], [0.3789635896682739], [0.0], [0.08019109070301056], [0.12216632068157196], [0.1200418621301651]]\n",
            "  Rule 111: IF x0 is mf1 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[1.0], [0.7505491971969604], [0.0], [0.2703609764575958], [0.7364773750305176], [0.6350767612457275]]\n",
            "  Rule 112: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.6163448095321655], [0.48851755261421204], [1.0], [0.5622835159301758], [0.6748334169387817]]\n",
            "  Rule 113: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.3640178442001343], [0.7106717824935913], [1.0], [0.41240352392196655], [0.2361627221107483]]\n",
            "  Rule 114: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.0036422312259674072], [0.9391050338745117], [1.0], [0.5018409490585327], [0.24776312708854675]]\n",
            "  Rule 115: IF x0 is mf1 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.0], [0.06465798616409302], [0.554132342338562], [0.2994999885559082], [0.5408768057823181], [1.0]]\n",
            "  Rule 116: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.39089563488960266], [0.27580198645591736], [0.0], [1.0], [0.43804940581321716], [0.6893190741539001]]\n",
            "  Rule 117: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.38184478878974915], [0.0], [1.0], [0.932388424873352], [0.7622320652008057], [0.7829948663711548]]\n",
            "  Rule 118: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.326918363571167], [0.0], [0.9999999403953552], [0.7413301467895508], [0.8185232877731323], [0.5408594012260437]]\n",
            "  Rule 119: IF x0 is mf1 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.7190091609954834], [0.0], [0.8487353324890137], [0.9999998807907104], [0.28853869438171387], [0.874897837638855]]\n",
            "  Rule 120: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.6992725729942322], [0.32922500371932983], [0.0], [1.0], [0.3724995255470276], [0.1585484743118286]]\n",
            "  Rule 121: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[1.0], [0.451931357383728], [0.5543331503868103], [0.9681217074394226], [0.0], [0.25559598207473755]]\n",
            "  Rule 122: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.5116412043571472], [0.5074502825737], [0.24636244773864746], [0.9999999403953552], [0.0], [0.4462260603904724]]\n",
            "  Rule 123: IF x0 is mf1 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.6212812662124634], [0.5982696413993835], [0.0], [1.0], [0.4417589604854584], [0.658334493637085]]\n",
            "  Rule 124: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.8859888315200806], [0.6517077088356018], [0.24356043338775635], [0.9999999403953552], [0.11187338829040527], [0.0]]\n",
            "  Rule 125: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.4100296199321747], [0.267689049243927], [0.33726879954338074], [1.0], [0.0], [0.12744921445846558]]\n",
            "  Rule 126: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.8135042190551758], [0.8960473537445068], [0.0], [0.9999999403953552], [0.7961307168006897], [0.781336784362793]]\n",
            "  Rule 127: IF x0 is mf1 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.7979955077171326], [0.9999998807907104], [0.0], [0.9926338195800781], [0.8438068628311157], [0.8972102403640747]]\n",
            "  Rule 128: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.756420373916626], [1.0], [0.805857241153717], [0.9196100831031799], [0.9982365965843201], [0.0]]\n",
            "  Rule 129: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.31728580594062805], [0.2767692804336548], [0.4833391010761261], [0.0], [0.19549883902072906], [1.0]]\n",
            "  Rule 130: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.02172735333442688], [0.0], [0.3354490399360657], [0.33105677366256714], [0.37962719798088074], [1.0]]\n",
            "  Rule 131: IF x0 is mf2 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.09896379709243774], [1.0], [0.0], [0.4563046991825104], [0.32147321105003357], [0.8565388917922974]]\n",
            "  Rule 132: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.2904101610183716], [0.19411621987819672], [1.0], [0.12370242178440094], [0.4376557767391205], [0.0]]\n",
            "  Rule 133: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.5724741220474243], [0.32040858268737793], [1.0], [0.36330288648605347], [0.5946056246757507], [0.0]]\n",
            "  Rule 134: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.8659895062446594], [0.1272279918193817], [1.0], [0.18551748991012573], [0.0], [0.4178770184516907]]\n",
            "  Rule 135: IF x0 is mf2 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.788225531578064], [0.31877201795578003], [0.03136706352233887], [0.0], [0.22236856818199158], [1.0]]\n",
            "  Rule 136: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.4893030822277069], [0.430231511592865], [0.9999998807907104], [0.03643926978111267], [0.5015411376953125], [0.0]]\n",
            "  Rule 137: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.5175915956497192], [1.0000001192092896], [0.5783851742744446], [0.4999871551990509], [0.7512137293815613], [0.0]]\n",
            "  Rule 138: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.3127356171607971], [0.9999999403953552], [0.15764525532722473], [0.137430340051651], [0.6005525588989258], [0.0]]\n",
            "  Rule 139: IF x0 is mf2 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[1.0], [0.5014631152153015], [0.3107561469078064], [0.5561274886131287], [0.0], [0.32398372888565063]]\n",
            "  Rule 140: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.4851786494255066], [0.4006662666797638], [1.0], [0.15173155069351196], [0.4837294816970825], [0.0]]\n",
            "  Rule 141: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.529991626739502], [1.0], [0.9620093703269958], [0.7213401794433594], [0.8458718061447144], [0.0]]\n",
            "  Rule 142: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.012512743473052979], [0.5871875286102295], [1.0], [0.5988754034042358], [0.6925317049026489], [0.0]]\n",
            "  Rule 143: IF x0 is mf2 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.6161997318267822], [0.0], [1.0], [0.8551725745201111], [0.5970738530158997], [0.8980022668838501]]\n",
            "  Rule 144: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.39045143127441406], [0.9999999403953552], [0.7242665886878967], [0.8355808854103088], [0.9346696138381958]]\n",
            "  Rule 145: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.5432487726211548], [1.0], [0.0], [0.5521245002746582], [0.42626306414604187], [0.3272855877876282]]\n",
            "  Rule 146: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.5646728277206421], [0.9999999403953552], [0.0], [0.4483027160167694], [0.44237321615219116], [0.5230421423912048]]\n",
            "  Rule 147: IF x0 is mf2 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.35380759835243225], [1.0], [0.7584195733070374], [0.8233765363693237], [0.8321223855018616], [0.0]]\n",
            "  Rule 148: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.0], [0.11478817462921143], [1.0], [0.2859553098678589], [0.37202590703964233], [0.5290452837944031]]\n",
            "  Rule 149: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.3021663427352905], [0.9999999403953552], [0.4653807282447815], [0.4011099338531494], [0.301187664270401]]\n",
            "  Rule 150: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.4555802047252655], [0.36622676253318787], [1.0], [0.0], [0.6518778204917908], [0.5806840658187866]]\n",
            "  Rule 151: IF x0 is mf2 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.8662235140800476], [0.46349772810935974], [0.5420120358467102], [0.5266485214233398], [1.0], [0.0]]\n",
            "  Rule 152: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.9137007594108582], [1.0], [0.7191281318664551], [0.3146679997444153], [0.9350004196166992], [0.0]]\n",
            "  Rule 153: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.9748360514640808], [0.7106664180755615], [0.3339034914970398], [0.0], [1.0], [0.29327529668807983]]\n",
            "  Rule 154: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.6022138595581055], [0.26086199283599854], [0.7559803128242493], [0.0], [1.0], [0.18175315856933594]]\n",
            "  Rule 155: IF x0 is mf2 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.3641015887260437], [0.41039764881134033], [0.5819845199584961], [0.3548750877380371], [0.0], [1.0]]\n",
            "  Rule 156: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.9178253412246704], [0.7544847726821899], [1.0], [0.5779954195022583], [0.516913652420044], [0.0]]\n",
            "  Rule 157: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.623485803604126], [0.0], [0.8620556592941284], [1.0], [0.6314665675163269], [0.3346782922744751]]\n",
            "  Rule 158: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.0], [0.20237600803375244], [0.2640250325202942], [0.9999998807907104], [0.3792383074760437], [0.4128395915031433]]\n",
            "  Rule 159: IF x0 is mf2 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.3804788589477539], [1.0], [0.0], [0.7646524906158447], [0.45174235105514526], [0.8569947481155396]]\n",
            "  Rule 160: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.37766140699386597], [0.3307127356529236], [1.0], [0.4657694101333618], [0.6404883861541748]]\n",
            "  Rule 161: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [1.0], [0.27823522686958313], [0.61003577709198], [0.34099042415618896], [0.12352770566940308]]\n",
            "  Rule 162: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.22379302978515625], [1.0], [0.0], [0.9577572345733643], [0.15806466341018677], [0.6161535382270813]]\n",
            "  Rule 163: IF x0 is mf2 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.20965790748596191], [0.9999999403953552], [0.11048838496208191], [0.5158742666244507], [0.0], [0.26301902532577515]]\n",
            "  Rule 164: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.1878187358379364], [0.430570125579834], [0.0], [0.9999999403953552], [0.3511178493499756], [0.5555883646011353]]\n",
            "  Rule 165: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.3690890967845917], [0.27178627252578735], [0.9999999403953552], [0.5172030925750732], [0.7458356022834778]]\n",
            "  Rule 166: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.3501092195510864], [0.26887381076812744], [0.0], [1.0], [0.8183555603027344], [0.18993529677391052]]\n",
            "  Rule 167: IF x0 is mf2 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.36976808309555054], [0.9999999403953552], [0.7328654527664185], [0.9924076199531555], [0.08063727617263794]]\n",
            "  Rule 168: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.23250794410705566], [1.0], [0.9813215732574463], [0.8333845138549805], [0.7397670745849609], [0.0]]\n",
            "  Rule 169: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.4596138000488281], [0.0], [0.9999999403953552], [0.709507942199707], [0.45250844955444336], [0.4220067262649536]]\n",
            "  Rule 170: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.21349650621414185], [0.5645666718482971], [1.0000001192092896], [0.0], [0.3244886100292206], [0.8979342579841614]]\n",
            "  Rule 171: IF x0 is mf2 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.33880341053009033], [0.7107380032539368], [0.9192852973937988], [0.03515887260437012], [1.0], [0.0]]\n",
            "  Rule 172: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.38537898659706116], [1.0], [0.9129130244255066], [0.8334509134292603], [0.0], [0.10941946506500244]]\n",
            "  Rule 173: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.9280165433883667], [0.8216469883918762], [0.0], [1.0], [0.4838649034500122], [0.3270455598831177]]\n",
            "  Rule 174: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.7841705679893494], [0.9081841707229614], [0.004571795463562012], [0.0], [0.7321274280548096], [1.0]]\n",
            "  Rule 175: IF x0 is mf2 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.8395887613296509], [0.14202791452407837], [0.9138776659965515], [0.18461060523986816], [0.9999999403953552], [0.0]]\n",
            "  Rule 176: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.0], [0.403715044260025], [0.3443021774291992], [1.0], [0.44004082679748535], [0.6230161190032959]]\n",
            "  Rule 177: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.13638180494308472], [0.9999999403953552], [0.021329015493392944], [0.5164794921875], [0.22374656796455383], [0.0]]\n",
            "  Rule 178: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.4404553771018982], [1.0], [0.0], [0.9315505623817444], [0.2566660940647125], [0.6356526017189026]]\n",
            "  Rule 179: IF x0 is mf2 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.4155445694923401], [1.0], [0.10795608162879944], [0.5908213257789612], [0.0], [0.3563587963581085]]\n",
            "  Rule 180: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.18391752243041992], [0.5018287897109985], [0.0], [1.0], [0.33899104595184326], [0.5437548160552979]]\n",
            "  Rule 181: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.8693115711212158], [0.22537502646446228], [1.0], [0.3252894878387451], [0.3967381417751312]]\n",
            "  Rule 182: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.42341750860214233], [0.6789764761924744], [0.0], [1.0000001192092896], [0.5522622466087341], [0.35641705989837646]]\n",
            "  Rule 183: IF x0 is mf2 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.8094280362129211], [0.0], [0.24234598875045776], [1.0], [0.6344991326332092], [0.3442901372909546]]\n",
            "  Rule 184: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.0], [1.0], [0.9803781509399414], [0.47498056292533875], [0.3253154456615448], [0.09230172634124756]]\n",
            "  Rule 185: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [1.0], [0.7457641959190369], [0.9524956941604614], [0.3347988724708557], [0.3805217444896698]]\n",
            "  Rule 186: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.0], [1.0], [0.742642879486084], [0.906852126121521], [0.23951581120491028], [0.671683669090271]]\n",
            "  Rule 187: IF x0 is mf2 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.7585949301719666], [0.30471575260162354], [0.871596097946167], [1.0], [0.0], [0.17385345697402954]]\n",
            "  Rule 188: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [1.0], [0.7319513559341431], [0.4236651659011841], [0.05773961544036865], [0.23264381289482117]]\n",
            "  Rule 189: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.38880810141563416], [1.0], [0.0], [0.6978408098220825], [0.21669112145900726], [0.11900857090950012]]\n",
            "  Rule 190: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[1.0], [0.8069226145744324], [0.0], [0.8824451565742493], [0.05764436721801758], [0.6684948205947876]]\n",
            "  Rule 191: IF x0 is mf2 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.7128718495368958], [1.0], [0.919808030128479], [0.9585155844688416], [0.826481819152832], [0.0]]\n",
            "  Rule 192: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.888384222984314], [0.5845794081687927], [0.6779564023017883], [0.9867111444473267], [1.0], [0.0]]\n",
            "  Rule 193: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.7338729500770569], [0.3220805823802948], [0.0], [1.0000001192092896], [0.5569441914558411], [0.6861767768859863]]\n",
            "  Rule 194: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.8938032388687134], [0.21988874673843384], [0.6372750997543335], [0.9066913723945618], [1.0], [0.0]]\n",
            "  Rule 195: IF x0 is mf3 and x1 is mf0 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.6548596024513245], [0.0], [1.0], [0.47005391120910645], [0.6178897023200989], [0.08372688293457031]]\n",
            "  Rule 196: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.4723254144191742], [0.32334232330322266], [1.0], [0.4706968665122986], [0.5484102964401245], [0.0]]\n",
            "  Rule 197: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.5655564069747925], [0.8048118948936462], [0.9596866965293884], [0.7654943466186523], [0.0]]\n",
            "  Rule 198: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.7089610695838928], [0.0], [0.8266462087631226], [1.0], [0.45333993434906006], [0.09820556640625]]\n",
            "  Rule 199: IF x0 is mf3 and x1 is mf0 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.7804136276245117], [0.0], [0.6130435466766357], [0.9561923742294312], [0.2893921434879303], [1.0]]\n",
            "  Rule 200: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.6615005731582642], [0.679703950881958], [1.0000001192092896], [0.458221435546875], [0.5536353588104248], [0.0]]\n",
            "  Rule 201: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.7471843957901001], [1.0], [0.6107351183891296], [0.5870541930198669], [0.5866140127182007], [0.0]]\n",
            "  Rule 202: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.7227429151535034], [0.6863135695457458], [1.0], [0.711327314376831], [0.07250016927719116], [0.0]]\n",
            "  Rule 203: IF x0 is mf3 and x1 is mf0 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[1.0], [0.15651926398277283], [0.7106767892837524], [0.8269121646881104], [0.0], [0.8128130435943604]]\n",
            "  Rule 204: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.6459190845489502], [0.6217662692070007], [1.0], [0.5400058031082153], [0.489193856716156], [0.0]]\n",
            "  Rule 205: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.9473498463630676], [1.0], [0.7752822637557983], [0.9133117198944092], [0.6957814693450928], [0.0]]\n",
            "  Rule 206: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.8329141139984131], [0.28752002120018005], [0.7913420796394348], [0.9999999403953552], [0.0], [0.1437911093235016]]\n",
            "  Rule 207: IF x0 is mf3 and x1 is mf0 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[1.0], [0.03851059079170227], [0.6239737272262573], [0.6071891784667969], [0.0], [0.7591532468795776]]\n",
            "  Rule 208: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.03404968976974487], [0.08673259615898132], [0.6576810479164124], [0.5791341066360474], [1.0], [0.0]]\n",
            "  Rule 209: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.8875285387039185], [0.5217658281326294], [0.0], [0.7330742478370667], [0.9999998807907104], [0.3906785249710083]]\n",
            "  Rule 210: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.4026447534561157], [0.0], [0.356271892786026], [0.5132156610488892], [1.0], [0.2637135088443756]]\n",
            "  Rule 211: IF x0 is mf3 and x1 is mf1 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.8773597478866577], [0.0], [0.16155606508255005], [0.4730684757232666], [1.0], [0.21273064613342285]]\n",
            "  Rule 212: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.39167189598083496], [1.0], [0.1391984224319458], [0.43992629647254944], [0.6987137794494629], [0.0]]\n",
            "  Rule 213: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[1.0], [0.9259523749351501], [0.23412668704986572], [0.6875845789909363], [0.41282010078430176], [0.0]]\n",
            "  Rule 214: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.7771750092506409], [1.0], [0.6560239195823669], [0.4534001052379608], [0.0], [0.29551589488983154]]\n",
            "  Rule 215: IF x0 is mf3 and x1 is mf1 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.14441505074501038], [0.5216872692108154], [0.0], [0.1942652016878128], [0.26602455973625183], [1.0]]\n",
            "  Rule 216: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.8146346211433411], [0.9999999403953552], [0.5859089493751526], [0.0], [0.8946458697319031], [0.06776934862136841]]\n",
            "  Rule 217: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[1.0000001192092896], [0.34802836179733276], [0.6488676071166992], [0.0], [0.3593962788581848], [0.07993733882904053]]\n",
            "  Rule 218: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[1.0], [0.17085711658000946], [0.0], [0.3375208079814911], [0.29490065574645996], [0.4234420359134674]]\n",
            "  Rule 219: IF x0 is mf3 and x1 is mf1 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.9999998807907104], [0.33548101782798767], [0.0], [0.6950433850288391], [0.42993366718292236], [0.8096215724945068]]\n",
            "  Rule 220: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.5655291080474854], [0.7105126976966858], [1.0], [0.18400853872299194], [0.5226526260375977], [0.0]]\n",
            "  Rule 221: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[1.0000001192092896], [0.1681535840034485], [0.0], [0.5427064895629883], [0.4790910482406616], [0.1097865104675293]]\n",
            "  Rule 222: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[1.0], [0.07399290800094604], [0.0], [0.7978882193565369], [0.3350571095943451], [0.7398654222488403]]\n",
            "  Rule 223: IF x0 is mf3 and x1 is mf1 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.6749441027641296], [1.0], [0.2376895248889923], [0.9484202861785889], [0.0], [0.5741907954216003]]\n",
            "  Rule 224: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.22461450099945068], [0.5391499996185303], [0.0], [0.7650776505470276], [0.9999999403953552], [0.5959705114364624]]\n",
            "  Rule 225: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.0], [0.15732380747795105], [0.061761677265167236], [0.34660106897354126], [1.0000001192092896], [0.15412166714668274]]\n",
            "  Rule 226: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.0], [0.4295588433742523], [1.0], [0.842404842376709], [0.9358925819396973], [0.986945390701294]]\n",
            "  Rule 227: IF x0 is mf3 and x1 is mf2 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.344784140586853], [0.0], [1.0], [0.09305515885353088], [0.12181654572486877], [0.6813094019889832]]\n",
            "  Rule 228: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.3544771075248718], [0.7690793871879578], [0.0], [0.5322692394256592], [1.0], [0.6602135896682739]]\n",
            "  Rule 229: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.0], [0.9786417484283447], [0.1704092025756836], [0.7709323167800903], [1.0000001192092896], [0.5515212416648865]]\n",
            "  Rule 230: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[0.0], [0.969120442867279], [0.7799452543258667], [0.6222304701805115], [0.9999999403953552], [0.1868734359741211]]\n",
            "  Rule 231: IF x0 is mf3 and x1 is mf2 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[0.0], [0.6313954591751099], [1.0], [0.5081602334976196], [0.7810659408569336], [0.23452383279800415]]\n",
            "  Rule 232: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.5080043077468872], [0.6536715626716614], [0.9999999403953552], [0.0], [0.8749496936798096], [0.4504498541355133]]\n",
            "  Rule 233: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[0.0], [0.26766079664230347], [1.0], [0.02803218364715576], [0.7085716128349304], [0.3663541078567505]]\n",
            "  Rule 234: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.05880570411682129], [0.002805173397064209], [1.0], [0.0], [0.9126549363136292], [0.45758822560310364]]\n",
            "  Rule 235: IF x0 is mf3 and x1 is mf2 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.8022434711456299], [0.9205268025398254], [1.0], [0.8466148376464844], [0.9787970781326294], [0.0]]\n",
            "  Rule 236: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.0], [0.6707996129989624], [1.0], [0.12457117438316345], [0.3928379416465759], [0.34205126762390137]]\n",
            "  Rule 237: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.3809081017971039], [0.835849404335022], [1.0], [0.0], [0.6944692730903625], [0.32041436433792114]]\n",
            "  Rule 238: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.23261964321136475], [0.7111498117446899], [0.9999999403953552], [0.0], [0.38806450366973877], [0.20445507764816284]]\n",
            "  Rule 239: IF x0 is mf3 and x1 is mf2 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[0.9516972303390503], [0.8420208692550659], [1.0], [0.7926630973815918], [0.9925893545150757], [0.0]]\n",
            "  Rule 240: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf0\n",
            "           THEN [[0.23229941725730896], [0.5185410380363464], [0.0], [0.7608484625816345], [1.0], [0.4660574197769165]]\n",
            "  Rule 241: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf1\n",
            "           THEN [[0.12128719687461853], [0.11568856239318848], [0.0], [0.4201728105545044], [1.0], [0.14345014095306396]]\n",
            "  Rule 242: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf2\n",
            "           THEN [[0.10944443941116333], [0.0], [1.0], [0.7073234915733337], [0.7211635708808899], [0.7931501269340515]]\n",
            "  Rule 243: IF x0 is mf3 and x1 is mf3 and x2 is mf0 and x3 is mf3\n",
            "           THEN [[0.8486690521240234], [0.0], [1.0], [0.3251192569732666], [0.05319741368293762], [0.5916610956192017]]\n",
            "  Rule 244: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf0\n",
            "           THEN [[0.08199179172515869], [0.42913195490837097], [0.0], [0.1246984601020813], [1.0], [0.29991254210472107]]\n",
            "  Rule 245: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf1\n",
            "           THEN [[0.6432067155838013], [0.8451744318008423], [0.0], [0.9989950656890869], [0.9999998807907104], [0.16135567426681519]]\n",
            "  Rule 246: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf2\n",
            "           THEN [[1.0], [0.28759390115737915], [0.0], [0.6697742938995361], [0.21964846551418304], [0.07390999794006348]]\n",
            "  Rule 247: IF x0 is mf3 and x1 is mf3 and x2 is mf1 and x3 is mf3\n",
            "           THEN [[1.0], [0.36868220567703247], [0.0], [0.49431344866752625], [0.11122116446495056], [0.1867171823978424]]\n",
            "  Rule 248: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf0\n",
            "           THEN [[0.3717387914657593], [0.6877464056015015], [1.0], [0.0], [0.693449079990387], [0.42847415804862976]]\n",
            "  Rule 249: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf1\n",
            "           THEN [[1.0], [0.4660671353340149], [0.41000550985336304], [0.6460016369819641], [0.4131886959075928], [0.0]]\n",
            "  Rule 250: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf2\n",
            "           THEN [[0.9305411577224731], [0.5340772271156311], [0.19086015224456787], [1.0], [0.6247715353965759], [0.0]]\n",
            "  Rule 251: IF x0 is mf3 and x1 is mf3 and x2 is mf2 and x3 is mf3\n",
            "           THEN [[0.8061398267745972], [0.8790810704231262], [0.8966736793518066], [0.9141775369644165], [1.0], [0.0]]\n",
            "  Rule 252: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf0\n",
            "           THEN [[0.9449124336242676], [1.0], [0.7200995087623596], [0.1601727306842804], [0.0], [0.22617366909980774]]\n",
            "  Rule 253: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf1\n",
            "           THEN [[0.9999999403953552], [0.4763804078102112], [0.9837625026702881], [0.29804641008377075], [0.6080535650253296], [0.0]]\n",
            "  Rule 254: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf2\n",
            "           THEN [[0.9971500635147095], [0.872269332408905], [1.0], [0.9208185076713562], [0.9027928709983826], [0.0]]\n",
            "  Rule 255: IF x0 is mf3 and x1 is mf3 and x2 is mf3 and x3 is mf3\n",
            "           THEN [[1.0], [0.9562914967536926], [0.969076931476593], [0.9911895394325256], [0.9549409747123718], [0.0]]\n",
            "  (layer): ModuleDict(\n",
            "    (fuzzify): Input variables\n",
            "    Variable x0\n",
            "    - mf0: GaussMembFunc(mu=23.97187614440918, sigma=28.415225982666016)\n",
            "    - mf1: GaussMembFunc(mu=66.7930679321289, sigma=27.876380920410156)\n",
            "    - mf2: GaussMembFunc(mu=115.59510040283203, sigma=29.43099594116211)\n",
            "    - mf3: GaussMembFunc(mu=153.0030517578125, sigma=30.676517486572266)\n",
            "    Variable x1\n",
            "    - mf0: GaussMembFunc(mu=16.422090530395508, sigma=30.838716506958008)\n",
            "    - mf1: GaussMembFunc(mu=90.98296356201172, sigma=34.837066650390625)\n",
            "    - mf2: GaussMembFunc(mu=129.0275115966797, sigma=31.68609619140625)\n",
            "    - mf3: GaussMembFunc(mu=189.4774932861328, sigma=42.342247009277344)\n",
            "    Variable x2\n",
            "    - mf0: GaussMembFunc(mu=30.621829986572266, sigma=26.665983200073242)\n",
            "    - mf1: GaussMembFunc(mu=76.13159942626953, sigma=28.235868453979492)\n",
            "    - mf2: GaussMembFunc(mu=117.28492736816406, sigma=27.32804298400879)\n",
            "    - mf3: GaussMembFunc(mu=193.09576416015625, sigma=44.86684036254883)\n",
            "    Variable x3\n",
            "    - mf0: GaussMembFunc(mu=0.9601664543151855, sigma=0.7270656228065491)\n",
            "    - mf1: GaussMembFunc(mu=2.5662436485290527, sigma=0.5928056836128235)\n",
            "    - mf2: GaussMembFunc(mu=3.735710382461548, sigma=0.49204930663108826)\n",
            "    - mf3: GaussMembFunc(mu=4.782688140869141, sigma=0.4762507975101471)\n",
            "    (rules): AntecedentLayer()\n",
            "    (consequent): PlainConsequentLayer()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RISULTATI TEST\n",
            "274390 of 353895 correct (accuracy=77.53%)\n",
            "tensor([5, 3, 1,  ..., 1, 3, 2])\n",
            "[[57420  3214  4201  2972   426    23]\n",
            " [ 5636 21771  3983  6771  2652   823]\n",
            " [ 5234  4364 49578  4543  1681   286]\n",
            " [ 6327  5069  2466 71491  4625  1001]\n",
            " [  825   528  4762  2431 30008    99]\n",
            " [   86   475   116  3766   120 44122]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.84      0.80     68256\n",
            "         1.0       0.61      0.52      0.57     41636\n",
            "         2.0       0.76      0.75      0.76     65686\n",
            "         3.0       0.78      0.79      0.78     90979\n",
            "         4.0       0.76      0.78      0.77     38653\n",
            "         5.0       0.95      0.91      0.93     48685\n",
            "\n",
            "    accuracy                           0.78    353895\n",
            "   macro avg       0.77      0.76      0.77    353895\n",
            "weighted avg       0.77      0.78      0.77    353895\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}